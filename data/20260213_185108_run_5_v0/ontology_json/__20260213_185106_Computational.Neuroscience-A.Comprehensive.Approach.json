{
  "@context": {
    "owl": "http://www.w3.org/2002/07/owl#",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "xsd": "http://www.w3.org/2001/XMLSchema#",
    "ns": "http://memebu.com/ontology/computationalneuroscienceacomprehensiveapproach#"
  },
  "@graph": [
    {
      "@id": "ns:Neuron",
      "@type": "owl:Class",
      "rdfs:label": "Neuron",
      "rdfs:comment": "A neuron is the fundamental computational unit of the nervous system. It receives inputs through dendrites, integrates them, and produces output through action potentials. Neurons exhibit both deterministic and stochastic dynamics and are characterized by their membrane properties, ion channel distributions, and connectivity patterns."
    },
    {
      "@id": "ns:PyramidalNeuron",
      "@type": "owl:Class",
      "rdfs:label": "Pyramidal Neuron",
      "rdfs:comment": "Pyramidal neurons are excitatory neurons found primarily in the cortex and hippocampus. They have a characteristic pyramid-shaped soma with an apical dendrite extending towards the cortical surface and basal dendrites radiating from the base. They form the majority of cortical neurons and are involved in higher cognitive functions.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:Interneuron",
      "@type": "owl:Class",
      "rdfs:label": "Interneuron",
      "rdfs:comment": "Interneurons are neurons that form connections between other neurons rather than directly connecting to sensory or motor systems. They are typically inhibitory and play crucial roles in modulating network activity, implementing gain control, and generating oscillations in neural circuits.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:IonChannel",
      "@type": "owl:Class",
      "rdfs:label": "Ion Channel",
      "rdfs:comment": "An ion channel is a membrane protein that forms a pore allowing specific ions to pass through the cell membrane. Ion channels can be voltage-gated, ligand-gated, or mechanically gated, and they are essential for neuronal excitability, signal transmission, and synaptic communication."
    },
    {
      "@id": "ns:SodiumChannel",
      "@type": "owl:Class",
      "rdfs:label": "Sodium Channel",
      "rdfs:comment": "Sodium channels are voltage-gated ion channels selective for sodium ions. They are responsible for the rapid depolarization phase of action potentials. They have fast activation and inactivation kinetics and are critical for the generation and propagation of spikes in excitable cells.",
      "rdfs:subClassOf": {
        "@id": "ns:IonChannel"
      }
    },
    {
      "@id": "ns:PotassiumChannel",
      "@type": "owl:Class",
      "rdfs:label": "Potassium Channel",
      "rdfs:comment": "Potassium channels are ion channels selective for potassium ions. They play crucial roles in repolarization after action potentials, setting resting membrane potential, and regulating neuronal excitability. Different types include delayed rectifier, A-type, and calcium-activated potassium channels.",
      "rdfs:subClassOf": {
        "@id": "ns:IonChannel"
      }
    },
    {
      "@id": "ns:CalciumChannel",
      "@type": "owl:Class",
      "rdfs:label": "Calcium Channel",
      "rdfs:comment": "Calcium channels are voltage-gated ion channels that allow calcium ions to enter cells. They mediate neurotransmitter release, trigger calcium-dependent processes, activate calcium-dependent enzymes, and contribute to action potential waveforms. Types include L-type, N-type, P/Q-type, and T-type channels.",
      "rdfs:subClassOf": {
        "@id": "ns:IonChannel"
      }
    },
    {
      "@id": "ns:Synapse",
      "@type": "owl:Class",
      "rdfs:label": "Synapse",
      "rdfs:comment": "A synapse is a junction between two neurons or between a neuron and a target cell where transmission of signals occurs. Synapses can be chemical (involving neurotransmitter release) or electrical (via gap junctions). They are the primary sites of neural plasticity and learning in the nervous system."
    },
    {
      "@id": "ns:ExcitatorySynapse",
      "@type": "owl:Class",
      "rdfs:label": "Excitatory Synapse",
      "rdfs:comment": "An excitatory synapse increases the probability that the postsynaptic neuron will fire an action potential. In the cortex, these synapses primarily use glutamate as their neurotransmitter and mediate depolarizing postsynaptic potentials through AMPA and NMDA receptors.",
      "rdfs:subClassOf": {
        "@id": "ns:Synapse"
      }
    },
    {
      "@id": "ns:InhibitorySynapse",
      "@type": "owl:Class",
      "rdfs:label": "Inhibitory Synapse",
      "rdfs:comment": "An inhibitory synapse decreases the probability that the postsynaptic neuron will fire an action potential. These synapses typically use GABA or glycine as neurotransmitters and cause hyperpolarization of the postsynaptic membrane, implementing gain control and preventing runaway excitation in neural circuits.",
      "rdfs:subClassOf": {
        "@id": "ns:Synapse"
      }
    },
    {
      "@id": "ns:Neurotransmitter",
      "@type": "owl:Class",
      "rdfs:label": "Neurotransmitter",
      "rdfs:comment": "A neurotransmitter is a chemical messenger released from presynaptic terminals that binds to receptors on postsynaptic cells to transmit signals across synapses. Major neurotransmitters include glutamate, GABA, acetylcholine, dopamine, serotonin, and norepinephrine, each with distinct functions in neural communication."
    },
    {
      "@id": "ns:Glutamate",
      "@type": "owl:Class",
      "rdfs:label": "Glutamate",
      "rdfs:comment": "Glutamate is the primary excitatory neurotransmitter in the central nervous system. It acts on ionotropic receptors (AMPA, NMDA, kainate) and metabotropic receptors to mediate fast excitatory transmission and plays crucial roles in synaptic plasticity, learning, and memory.",
      "rdfs:subClassOf": {
        "@id": "ns:Neurotransmitter"
      }
    },
    {
      "@id": "ns:GABA",
      "@type": "owl:Class",
      "rdfs:label": "GABA",
      "rdfs:comment": "Gamma-aminobutyric acid (GABA) is the primary inhibitory neurotransmitter in the central nervous system. It acts on GABA-A receptors (ionotropic) and GABA-B receptors (metabotropic) to hyperpolarize neurons and reduce their firing probability, essential for maintaining excitation-inhibition balance in neural networks.",
      "rdfs:subClassOf": {
        "@id": "ns:Neurotransmitter"
      }
    },
    {
      "@id": "ns:NeuronalModel",
      "@type": "owl:Class",
      "rdfs:label": "Neuronal Model",
      "rdfs:comment": "A neuronal model is a mathematical or computational representation of neuronal dynamics. Models range from simple integrate-and-fire neurons to detailed biophysical models with multiple compartments and ion channel types. They are used to understand information processing, predict neural responses, and test hypotheses about neural function."
    },
    {
      "@id": "ns:IntegrateAndFireModel",
      "@type": "owl:Class",
      "rdfs:label": "Integrate-and-Fire Model",
      "rdfs:comment": "The integrate-and-fire model is a simplified neuronal model where the membrane potential integrates incoming currents until reaching a threshold, at which point a spike is generated and the potential is reset. This model captures essential spike generation dynamics while remaining computationally tractable for large network simulations.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuronalModel"
      }
    },
    {
      "@id": "ns:HodgkinHuxleyModel",
      "@type": "owl:Class",
      "rdfs:label": "Hodgkin-Huxley Model",
      "rdfs:comment": "The Hodgkin-Huxley model is a detailed biophysical model describing action potential generation through voltage-gated sodium and potassium channel dynamics. It uses differential equations to model channel gating variables and reproduces the full time course of action potentials. This foundational model established the ionic basis of excitability.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuronalModel"
      }
    },
    {
      "@id": "ns:FitzHughNagumoModel",
      "@type": "owl:Class",
      "rdfs:label": "FitzHugh-Nagumo Model",
      "rdfs:comment": "The FitzHugh-Nagumo model is a simplified two-variable model of neuronal excitability derived from the Hodgkin-Huxley equations. It captures the essential dynamics of excitable systems including threshold behavior, refractoriness, and oscillatory activity, making it useful for theoretical analysis of neural dynamics.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuronalModel"
      }
    },
    {
      "@id": "ns:ActionPotential",
      "@type": "owl:Class",
      "rdfs:label": "Action Potential",
      "rdfs:comment": "An action potential is a rapid, transient change in membrane potential that propagates along axons to transmit information over long distances. It consists of depolarization driven by sodium influx followed by repolarization due to potassium efflux. Action potentials are all-or-none events that form the basis of neural signaling."
    },
    {
      "@id": "ns:MembranePotential",
      "@type": "owl:Class",
      "rdfs:label": "Membrane Potential",
      "rdfs:comment": "Membrane potential is the electrical potential difference across the cell membrane, typically around -70mV at rest in neurons. It results from the distribution of ions across the membrane and their selective permeability. Changes in membrane potential underlie all electrical signaling in neurons including synaptic potentials and action potentials."
    },
    {
      "@id": "ns:SynapticPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Synaptic Plasticity",
      "rdfs:comment": "Synaptic plasticity refers to activity-dependent changes in synaptic strength that can last from milliseconds to years. It is the cellular basis of learning and memory, allowing neural circuits to adapt based on experience. Major forms include long-term potentiation, long-term depression, and spike-timing-dependent plasticity."
    },
    {
      "@id": "ns:LongTermPotentiation",
      "@type": "owl:Class",
      "rdfs:label": "Long-Term Potentiation",
      "rdfs:comment": "Long-term potentiation (LTP) is a persistent strengthening of synapses based on recent patterns of activity. It is induced by high-frequency stimulation or coincident pre- and postsynaptic activity, requires NMDA receptor activation in many synapses, and involves both presynaptic and postsynaptic mechanisms. LTP is a major cellular mechanism underlying memory formation.",
      "rdfs:subClassOf": {
        "@id": "ns:SynapticPlasticity"
      }
    },
    {
      "@id": "ns:LongTermDepression",
      "@type": "owl:Class",
      "rdfs:label": "Long-Term Depression",
      "rdfs:comment": "Long-term depression (LTD) is a persistent weakening of synaptic connections resulting from specific patterns of activity. It can be induced by low-frequency stimulation or asynchronous pre- and postsynaptic activity. LTD works in concert with LTP to refine neural circuits, prevent saturation of synaptic weights, and sculpt receptive fields during development and learning.",
      "rdfs:subClassOf": {
        "@id": "ns:SynapticPlasticity"
      }
    },
    {
      "@id": "ns:SpikeTimingDependentPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Spike-Timing-Dependent Plasticity",
      "rdfs:comment": "Spike-timing-dependent plasticity (STDP) is a form of synaptic plasticity where the change in synaptic strength depends on the precise timing between presynaptic and postsynaptic spikes. If the presynaptic spike precedes the postsynaptic spike within a critical window (typically 20ms), the synapse is strengthened; if the order is reversed, it is weakened. This implements a causality-based learning rule.",
      "rdfs:subClassOf": {
        "@id": "ns:SynapticPlasticity"
      }
    },
    {
      "@id": "ns:Dendrite",
      "@type": "owl:Class",
      "rdfs:label": "Dendrite",
      "rdfs:comment": "Dendrites are branched neuronal processes that receive synaptic inputs from other neurons. They integrate these inputs through passive and active electrical properties, with some dendrites capable of generating local spikes. Dendritic morphology and active properties significantly influence neuronal computation and synaptic integration."
    },
    {
      "@id": "ns:Axon",
      "@type": "owl:Class",
      "rdfs:label": "Axon",
      "rdfs:comment": "The axon is the neuronal process that transmits action potentials away from the cell body to synaptic terminals. Axons can extend over long distances and are often myelinated to increase conduction velocity. The axon initial segment is the site where action potentials typically initiate due to high density of voltage-gated sodium channels."
    },
    {
      "@id": "ns:Soma",
      "@type": "owl:Class",
      "rdfs:label": "Soma",
      "rdfs:comment": "The soma or cell body is the central part of the neuron containing the nucleus and most cellular organelles. It integrates dendritic inputs and generates the output that propagates down the axon. The soma's membrane properties and ion channel composition influence the neuron's input-output transformation and firing patterns."
    },
    {
      "@id": "ns:NeuralNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Neural Network",
      "rdfs:comment": "A neural network is a collection of interconnected neurons that process information collectively. Networks can exhibit emergent properties not present in individual neurons including oscillations, synchronization, pattern completion, and memory storage. Network architecture and connectivity patterns determine computational capabilities and functional properties."
    },
    {
      "@id": "ns:RecurrentNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Recurrent Network",
      "rdfs:comment": "A recurrent network contains feedback connections from neurons to themselves or to neurons in the same or previous layers. These networks can maintain persistent activity states, implement attractor dynamics, and store information in their connection patterns. They are crucial for working memory, sequence generation, and temporal processing.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuralNetwork"
      }
    },
    {
      "@id": "ns:FeedforwardNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Feedforward Network",
      "rdfs:comment": "A feedforward network has connections that flow in one direction from input to output layers without feedback loops. These networks perform hierarchical processing, feature extraction, and transformation of sensory inputs. The visual system exemplifies feedforward processing from retina through successive cortical areas.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuralNetwork"
      }
    },
    {
      "@id": "ns:AttractorNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Attractor Network",
      "rdfs:comment": "An attractor network is a recurrent network with stable states (attractors) to which the network dynamics converge. These networks can store patterns as attractors, perform pattern completion from partial cues, and implement associative memory. Attractor networks are theoretical models for working memory, decision making, and episodic memory in the hippocampus.",
      "rdfs:subClassOf": {
        "@id": "ns:RecurrentNetwork"
      }
    },
    {
      "@id": "ns:ContinuousAttractorNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Continuous Attractor Network",
      "rdfs:comment": "A continuous attractor network has a continuous manifold of stable states rather than discrete attractors. These networks can represent continuous variables like head direction, spatial position, or eye position. They support smooth interpolation between states and can integrate velocity signals to update position representations, as seen in path integration and spatial navigation.",
      "rdfs:subClassOf": {
        "@id": "ns:AttractorNetwork"
      }
    },
    {
      "@id": "ns:Hippocampus",
      "@type": "owl:Class",
      "rdfs:label": "Hippocampus",
      "rdfs:comment": "The hippocampus is a brain structure crucial for episodic memory formation and spatial navigation. It contains place cells that encode spatial locations and supports rapid one-shot learning of new episodes. The hippocampus has distinct subregions (CA1, CA3, dentate gyrus) with specialized connectivity patterns implementing pattern separation and completion."
    },
    {
      "@id": "ns:PrefrontalCortex",
      "@type": "owl:Class",
      "rdfs:label": "Prefrontal Cortex",
      "rdfs:comment": "The prefrontal cortex is the anterior part of the frontal lobe involved in executive functions, working memory, decision making, and cognitive control. It maintains information in working memory through persistent neural activity during delay periods and coordinates behavior across time. The prefrontal cortex shows extensive reciprocal connections with posterior sensory and motor areas."
    },
    {
      "@id": "ns:VisualCortex",
      "@type": "owl:Class",
      "rdfs:label": "Visual Cortex",
      "rdfs:comment": "The visual cortex processes visual information in a hierarchical manner from primary visual cortex (V1) through successive extrastriate areas (V2, V4, MT, IT). Early areas encode local features like oriented edges while higher areas represent complex objects, faces, and scenes. The ventral stream processes object identity while the dorsal stream processes spatial location and motion."
    },
    {
      "@id": "ns:MotorCortex",
      "@type": "owl:Class",
      "rdfs:label": "Motor Cortex",
      "rdfs:comment": "The motor cortex is involved in planning, control, and execution of voluntary movements. It includes primary motor cortex, premotor cortex, and supplementary motor areas. Motor cortex neurons encode movement parameters like direction, force, and velocity, and send commands to spinal cord motor neurons via the corticospinal tract."
    },
    {
      "@id": "ns:Cerebellum",
      "@type": "owl:Class",
      "rdfs:label": "Cerebellum",
      "rdfs:comment": "The cerebellum is crucial for motor coordination, motor learning, and timing. It receives sensory input and motor command copies, compares intended with actual movements, and adjusts motor output through learning. The cerebellar cortex has a highly regular architecture with granule cells, Purkinje cells, and various interneurons implementing predictive motor control."
    },
    {
      "@id": "ns:Amygdala",
      "@type": "owl:Class",
      "rdfs:label": "Amygdala",
      "rdfs:comment": "The amygdala is a subcortical structure central to emotional processing, fear conditioning, and reward learning. It associates sensory stimuli with emotional significance through pattern association learning. The amygdala projects widely to cortical and subcortical structures to modulate perception, memory, and behavioral responses based on emotional salience."
    },
    {
      "@id": "ns:PlaceCell",
      "@type": "owl:Class",
      "rdfs:label": "Place Cell",
      "rdfs:comment": "Place cells are hippocampal neurons that fire when an animal is in a specific location in its environment. Each place cell has a place field where it fires maximally. Populations of place cells provide a cognitive map of space used for navigation and episodic memory. Place representations can remap when environmental cues change."
    },
    {
      "@id": "ns:HeadDirectionCell",
      "@type": "owl:Class",
      "rdfs:label": "Head Direction Cell",
      "rdfs:comment": "Head direction cells fire when an animal's head points in a specific direction regardless of location. Found in multiple brain regions including presubiculum and anterior thalamus, they form a neural compass. Head direction is maintained by a continuous attractor network that integrates angular velocity signals from the vestibular system."
    },
    {
      "@id": "ns:GridCell",
      "@type": "owl:Class",
      "rdfs:label": "Grid Cell",
      "rdfs:comment": "Grid cells in entorhinal cortex fire at multiple locations forming a hexagonal grid pattern across the environment. They provide a metric coordinate system for spatial navigation. Grid cells have different spatial scales and orientations, and their activity patterns are thought to contribute to path integration and the generation of place cell firing."
    },
    {
      "@id": "ns:CalciumSignaling",
      "@type": "owl:Class",
      "rdfs:label": "Calcium Signaling",
      "rdfs:comment": "Calcium signaling involves changes in intracellular calcium concentration that trigger various cellular processes. In neurons, calcium enters through voltage-gated channels, NMDA receptors, and is released from internal stores. Calcium acts as a second messenger regulating neurotransmitter release, gene expression, synaptic plasticity, and can trigger cell death at high concentrations."
    },
    {
      "@id": "ns:CalciumBuffer",
      "@type": "owl:Class",
      "rdfs:label": "Calcium Buffer",
      "rdfs:comment": "Calcium buffers are proteins that bind calcium ions to regulate spatial and temporal aspects of calcium signaling. Buffers include calbindin, calretinin, parvalbumin, and calmodulin. They reduce free calcium concentration, slow calcium diffusion, and shape calcium transients. Buffer properties influence synaptic plasticity, excitability, and calcium-dependent processes."
    },
    {
      "@id": "ns:Receptor",
      "@type": "owl:Class",
      "rdfs:label": "Receptor",
      "rdfs:comment": "Receptors are proteins that bind specific molecules (ligands) and transduce signals across cell membranes. In neurons, receptors include ionotropic receptors (ligand-gated ion channels) and metabotropic receptors (G-protein coupled). Receptors mediate responses to neurotransmitters, neuromodulators, and other signaling molecules."
    },
    {
      "@id": "ns:AMPAReceptor",
      "@type": "owl:Class",
      "rdfs:label": "AMPA Receptor",
      "rdfs:comment": "AMPA receptors are ionotropic glutamate receptors that mediate fast excitatory synaptic transmission. They are permeable to sodium and potassium ions, have fast kinetics, and produce rapid depolarization. AMPA receptor trafficking and modification are key mechanisms in synaptic plasticity including LTP and LTD.",
      "rdfs:subClassOf": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:NMDAReceptor",
      "@type": "owl:Class",
      "rdfs:label": "NMDA Receptor",
      "rdfs:comment": "NMDA receptors are ionotropic glutamate receptors with unique properties including voltage-dependent magnesium block and calcium permeability. They require both glutamate binding and postsynaptic depolarization to open, acting as coincidence detectors. NMDA receptors are crucial for synaptic plasticity, learning, and development but can mediate excitotoxicity when overactivated.",
      "rdfs:subClassOf": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:GABAReceptor",
      "@type": "owl:Class",
      "rdfs:label": "GABA Receptor",
      "rdfs:comment": "GABA receptors mediate inhibitory neurotransmission. GABA-A receptors are ionotropic, permeable to chloride, and produce fast inhibition. GABA-B receptors are metabotropic, G-protein coupled, and produce slow, prolonged inhibition. GABA receptors are targets for anxiolytics, sedatives, and anticonvulsants.",
      "rdfs:subClassOf": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:DynamicalSystem",
      "@type": "owl:Class",
      "rdfs:label": "Dynamical System",
      "rdfs:comment": "A dynamical system describes how a system evolves over time according to rules specified by differential or difference equations. Neural systems exhibit rich dynamics including fixed points, limit cycles, chaos, and bifurcations. Dynamical systems theory provides tools for analyzing stability, attractors, and transitions between different activity states in neural circuits."
    },
    {
      "@id": "ns:Bifurcation",
      "@type": "owl:Class",
      "rdfs:label": "Bifurcation",
      "rdfs:comment": "A bifurcation is a qualitative change in the behavior of a dynamical system as a parameter is varied. In neural systems, bifurcations explain transitions between quiescence and firing, changes in firing patterns, and switches between network states. Common bifurcations include saddle-node, Hopf, and pitchfork bifurcations."
    },
    {
      "@id": "ns:StochasticProcess",
      "@type": "owl:Class",
      "rdfs:label": "Stochastic Process",
      "rdfs:comment": "A stochastic process is a random process evolving over time. In neuroscience, stochastic processes model channel noise, synaptic variability, and irregular firing patterns. Poisson processes model random spike trains, diffusion processes model membrane potential fluctuations, and Markov processes model ion channel gating."
    },
    {
      "@id": "ns:MarkovProcess",
      "@type": "owl:Class",
      "rdfs:label": "Markov Process",
      "rdfs:comment": "A Markov process is a stochastic process where future states depend only on the current state, not on past history. Ion channel gating is modeled as a Markov process with discrete states and voltage-dependent transition rates. Markov models enable prediction of macroscopic currents from single channel kinetics.",
      "rdfs:subClassOf": {
        "@id": "ns:StochasticProcess"
      }
    },
    {
      "@id": "ns:PoissonProcess",
      "@type": "owl:Class",
      "rdfs:label": "Poisson Process",
      "rdfs:comment": "A Poisson process is a stochastic point process where events occur randomly and independently at a constant average rate. Many neural spike trains approximate Poisson statistics with coefficient of variation near 1. Poisson models are used for synaptic input, spontaneous release, and as null hypotheses for analyzing temporal structure in spike trains.",
      "rdfs:subClassOf": {
        "@id": "ns:StochasticProcess"
      }
    },
    {
      "@id": "ns:InformationTheory",
      "@type": "owl:Class",
      "rdfs:label": "Information Theory",
      "rdfs:comment": "Information theory quantifies the information content of signals and the efficiency of neural codes. Key concepts include entropy (uncertainty), mutual information (shared information between stimulus and response), and Fisher information (precision of parameter estimation). Information theory provides principled methods for analyzing neural coding and optimal encoding strategies."
    },
    {
      "@id": "ns:MutualInformation",
      "@type": "owl:Class",
      "rdfs:label": "Mutual Information",
      "rdfs:comment": "Mutual information quantifies the amount of information that one variable provides about another. In neuroscience, it measures how much information neural responses carry about stimuli or behavioral variables. Mutual information accounts for all statistical dependencies and provides a model-free measure of neural coding efficiency."
    },
    {
      "@id": "ns:ShannonEntropy",
      "@type": "owl:Class",
      "rdfs:label": "Shannon Entropy",
      "rdfs:comment": "Shannon entropy quantifies the uncertainty or information content of a random variable. For discrete variables, entropy is the expected negative log probability. In neural coding, entropy of spike patterns indicates coding capacity. Maximum entropy principle predicts neural response distributions from measured statistics."
    },
    {
      "@id": "ns:NeuralCode",
      "@type": "owl:Class",
      "rdfs:label": "Neural Code",
      "rdfs:comment": "Neural code refers to how information is represented in patterns of neural activity. Proposed codes include rate codes (information in firing rates), temporal codes (information in precise spike timing), and population codes (information distributed across neurons). The nature of neural codes remains debated and may vary across brain regions and tasks."
    },
    {
      "@id": "ns:RateCoding",
      "@type": "owl:Class",
      "rdfs:label": "Rate Coding",
      "rdfs:comment": "Rate coding is a neural coding scheme where information is carried by the average firing rate of neurons over a time window. Rate codes are robust to noise and timing jitter. Evidence for rate coding includes correlations between firing rates and sensory stimuli or motor variables in many brain areas.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuralCode"
      }
    },
    {
      "@id": "ns:TemporalCoding",
      "@type": "owl:Class",
      "rdfs:label": "Temporal Coding",
      "rdfs:comment": "Temporal coding uses precise timing of spikes relative to external events or other spikes to carry information. Evidence includes precise spike timing in sensory systems, phase coding relative to network oscillations, and synfire chains. Temporal codes can transmit information faster than rate codes and encode additional dimensions of stimuli.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuralCode"
      }
    },
    {
      "@id": "ns:PopulationCoding",
      "@type": "owl:Class",
      "rdfs:label": "Population Coding",
      "rdfs:comment": "Population coding distributes information across many neurons with overlapping tuning curves. Populations can represent multiple variables simultaneously and achieve higher accuracy than individual neurons through averaging. Population vector methods decode represented variables from population activity in motor and sensory systems.",
      "rdfs:subClassOf": {
        "@id": "ns:NeuralCode"
      }
    },
    {
      "@id": "ns:MotionDetection",
      "@type": "owl:Class",
      "rdfs:label": "Motion Detection",
      "rdfs:comment": "Motion detection extracts the direction and speed of moving stimuli from spatiotemporal patterns of receptor activation. The Reichardt correlation detector model explains motion detection in insects through spatially offset inputs with temporal delays. Motion detectors exhibit direction selectivity and velocity tuning and form the basis for optic flow processing."
    },
    {
      "@id": "ns:ReichardtDetector",
      "@type": "owl:Class",
      "rdfs:label": "Reichardt Detector",
      "rdfs:comment": "The Reichardt detector is a model for motion detection using correlation of temporally filtered signals from spatially offset inputs. It consists of mirror-symmetric subunits that multiply delayed and non-delayed signals. The model accounts for direction selectivity, velocity tuning, and pattern dependence in insect motion vision and has influenced understanding of vertebrate motion detection.",
      "rdfs:subClassOf": {
        "@id": "ns:MotionDetection"
      }
    },
    {
      "@id": "ns:CompartmentalModel",
      "@type": "owl:Class",
      "rdfs:label": "Compartmental Model",
      "rdfs:comment": "A compartmental model represents a neuron as multiple connected compartments, each with uniform electrical properties. This approach captures spatial variation in membrane potential, dendritic integration, and the effects of morphology on neuronal computation. Compartmental models are based on cable theory and use systems of coupled differential equations."
    },
    {
      "@id": "ns:CableTheory",
      "@type": "owl:Class",
      "rdfs:label": "Cable Theory",
      "rdfs:comment": "Cable theory describes the passive spread of electrical signals along dendrites and axons treated as cylindrical cables. It predicts voltage attenuation, time constants, and electrotonic length based on membrane resistance, internal resistance, and capacitance. Cable theory is fundamental for understanding dendritic integration and synaptic efficacy."
    },
    {
      "@id": "ns:SpatialMemory",
      "@type": "owl:Class",
      "rdfs:label": "Spatial Memory",
      "rdfs:comment": "Spatial memory encodes and retrieves information about locations and spatial relationships in the environment. The hippocampus is critical for spatial memory in mammals, with place cells and grid cells providing neural substrates. Spatial memory involves both allocentric (world-centered) and egocentric (self-centered) reference frames and supports navigation."
    },
    {
      "@id": "ns:EpisodicMemory",
      "@type": "owl:Class",
      "rdfs:label": "Episodic Memory",
      "rdfs:comment": "Episodic memory stores and retrieves specific events with their spatial and temporal context. The hippocampus and associated medial temporal lobe structures are essential for episodic memory formation. Computational models propose the hippocampus implements rapid one-shot learning through pattern separation in dentate gyrus and pattern completion in CA3."
    },
    {
      "@id": "ns:WorkingMemory",
      "@type": "owl:Class",
      "rdfs:label": "Working Memory",
      "rdfs:comment": "Working memory maintains and manipulates information over short periods for ongoing cognitive tasks. Prefrontal cortex sustains working memory representations through persistent neural activity in attractor states. Working memory has limited capacity and requires active maintenance through recurrent excitation. It is distinct from perceptual systems to allow processing of new stimuli."
    },
    {
      "@id": "ns:LearningRule",
      "@type": "owl:Class",
      "rdfs:label": "Learning Rule",
      "rdfs:comment": "A learning rule specifies how synaptic weights change based on neural activity. Rules include Hebbian learning (fire together, wire together), spike-timing-dependent plasticity, and error-driven learning. Learning rules determine what computations networks can learn, their storage capacity, and the nature of learned representations."
    },
    {
      "@id": "ns:HebbianLearning",
      "@type": "owl:Class",
      "rdfs:label": "Hebbian Learning",
      "rdfs:comment": "Hebbian learning strengthens synapses between neurons that are repeatedly active together, implementing the principle that cells that fire together wire together. This correlation-based learning extracts statistical regularities from input patterns and forms the basis for associative memory, development of receptive fields, and unsupervised learning in neural networks.",
      "rdfs:subClassOf": {
        "@id": "ns:LearningRule"
      }
    },
    {
      "@id": "ns:Oscillation",
      "@type": "owl:Class",
      "rdfs:label": "Oscillation",
      "rdfs:comment": "Neural oscillations are rhythmic fluctuations in neural activity occurring at various frequencies. They arise from network interactions and intrinsic neuronal properties. Oscillations include delta, theta, alpha, beta, and gamma rhythms. They may coordinate neural activity across areas, provide temporal windows for plasticity, and route information through phase-dependent communication."
    },
    {
      "@id": "ns:Synchronization",
      "@type": "owl:Class",
      "rdfs:label": "Synchronization",
      "rdfs:comment": "Synchronization refers to correlated firing among neurons or brain regions. It can emerge from common inputs, direct synaptic connections, or weak coupling through oscillations. Synchronization affects information transmission, binding of features, and effective connectivity. Abnormal synchronization is implicated in epilepsy, Parkinson's disease, and other neurological disorders."
    },
    {
      "@id": "ns:SensoryProcessing",
      "@type": "owl:Class",
      "rdfs:label": "Sensory Processing",
      "rdfs:comment": "Sensory processing transforms physical stimuli into neural representations through hierarchical processing in sensory pathways. Early stages extract local features while later stages build increasingly complex and invariant representations. Sensory processing involves feedforward feature extraction, lateral interactions for gain control and normalization, and top-down modulation by attention and expectation."
    },
    {
      "@id": "ns:ReceptiveField",
      "@type": "owl:Class",
      "rdfs:label": "Receptive Field",
      "rdfs:comment": "A receptive field is the region of sensory space where stimuli influence a neuron's firing. Receptive fields are characterized by their size, shape, preferred stimulus features, and spatial structure. Hierarchical processing builds larger, more complex receptive fields from simpler ones. Receptive field properties emerge from connectivity patterns and can be modified by learning."
    },
    {
      "@id": "ns:FeatureDetector",
      "@type": "owl:Class",
      "rdfs:label": "Feature Detector",
      "rdfs:comment": "A feature detector is a neuron or circuit that selectively responds to specific stimulus features like oriented edges, motion direction, or spatial frequency. Feature detectors implement filtering operations that extract relevant information while discarding irrelevant variations. They form the basis of hierarchical sensory processing and can emerge through unsupervised learning."
    },
    {
      "@id": "ns:InvariantRepresentation",
      "@type": "owl:Class",
      "rdfs:label": "Invariant Representation",
      "rdfs:comment": "Invariant representations maintain selectivity for objects or features despite transformations like position, size, viewpoint, or lighting changes. The ventral visual stream achieves invariance through hierarchical processing with progressively larger receptive fields and pooling operations. Invariance enables object recognition and is learned through experience with transformed stimuli via temporal continuity."
    },
    {
      "@id": "ns:GainControl",
      "@type": "owl:Class",
      "rdfs:label": "Gain Control",
      "rdfs:comment": "Gain control adjusts the sensitivity or response amplitude of neurons or circuits based on stimulus statistics or behavioral context. Mechanisms include divisive normalization, synaptic depression, and inhibitory feedback. Gain control maintains neural responses within dynamic range, implements adaptation, and optimizes coding efficiency across different stimulus conditions."
    },
    {
      "@id": "ns:DentategyrusGranuleCell",
      "@type": "owl:Class",
      "rdfs:label": "Dentate Gyrus Granule Cell",
      "rdfs:comment": "Dentate gyrus granule cells are the input neurons of the hippocampus, receiving cortical information from entorhinal cortex via the perforant path. Their sparse firing and competitive dynamics implement pattern separation, orthogonalizing similar input patterns. This reduces interference in downstream CA3 memory storage and enables discrimination of similar experiences.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:CA3PyramidalCell",
      "@type": "owl:Class",
      "rdfs:label": "CA3 Pyramidal Cell",
      "rdfs:comment": "CA3 pyramidal cells form an extensively recurrent network in the hippocampus with strong recurrent collateral connections. This architecture implements an autoassociative network for rapid one-shot learning and pattern completion in episodic memory. CA3 receives input from dentate gyrus and entorhinal cortex and projects to CA1 and contralateral hippocampus.",
      "rdfs:subClassOf": {
        "@id": "ns:PyramidalNeuron"
      }
    },
    {
      "@id": "ns:CA1PyramidalCell",
      "@type": "owl:Class",
      "rdfs:label": "CA1 Pyramidal Cell",
      "rdfs:comment": "CA1 pyramidal cells are the major output neurons of the hippocampus. They receive strong input from CA3 via Schaffer collaterals and direct entorhinal input via temporoammonic pathway. CA1 may compare these two inputs to detect novelty or mismatch and consolidates hippocampal representations for transfer to neocortex during sleep and rest.",
      "rdfs:subClassOf": {
        "@id": "ns:PyramidalNeuron"
      }
    },
    {
      "@id": "ns:PurkinjeCell",
      "@type": "owl:Class",
      "rdfs:label": "Purkinje Cell",
      "rdfs:comment": "Purkinje cells are the sole output neurons of the cerebellar cortex with elaborate dendritic trees receiving massive parallel fiber and climbing fiber inputs. They exhibit complex spike and simple spike firing patterns. Purkinje cells implement supervised learning through climbing fiber teaching signals that modify parallel fiber synapses, enabling motor learning and coordination.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:GranuleCell",
      "@type": "owl:Class",
      "rdfs:label": "Granule Cell",
      "rdfs:comment": "Granule cells are small neurons found in cerebellum and dentate gyrus. Cerebellar granule cells are the most numerous neurons in the brain, receiving mossy fiber input and sending parallel fibers to Purkinje cells. They implement sparse expansion recoding that increases pattern separability. Dentate gyrus granule cells perform similar pattern separation for hippocampal memory.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:BasketCell",
      "@type": "owl:Class",
      "rdfs:label": "Basket Cell",
      "rdfs:comment": "Basket cells are GABAergic interneurons that provide perisomatic inhibition to pyramidal cells through extensive axonal arbors. They are fast-spiking and well-connected through gap junctions, enabling synchronized inhibition. Basket cells implement gain control, regulate excitability, generate gamma oscillations, and define temporal windows for synaptic integration and plasticity.",
      "rdfs:subClassOf": {
        "@id": "ns:Interneuron"
      }
    },
    {
      "@id": "ns:MitralCell",
      "@type": "owl:Class",
      "rdfs:label": "Mitral Cell",
      "rdfs:comment": "Mitral cells are the principal output neurons of the olfactory bulb, projecting to olfactory cortex. Each mitral cell receives input from one glomerulus representing a single odorant receptor type. They form dendrodendritic reciprocal synapses with granule cells, implementing lateral inhibition and gain control. Mitral cell firing patterns encode odor identity and intensity.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:SpinyStellateCell",
      "@type": "owl:Class",
      "rdfs:label": "Spiny Stellate Cell",
      "rdfs:comment": "Spiny stellate cells are excitatory interneurons in cortical layer 4 that receive thalamic input and project locally within cortical columns. They have radially symmetric dendritic arbors and provide initial cortical processing of sensory information. In visual cortex, they exhibit orientation selectivity and distribute thalamic input to pyramidal cells in superficial and deep layers.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:ChannelNoise",
      "@type": "owl:Class",
      "rdfs:label": "Channel Noise",
      "rdfs:comment": "Channel noise arises from stochastic opening and closing of ion channels according to their voltage-dependent transition rates. For small numbers of channels, noise significantly affects membrane potential fluctuations and spike timing variability. Channel noise power depends on channel density, conductance, and open probability, with maximum noise at intermediate open probabilities."
    },
    {
      "@id": "ns:SynapticNoise",
      "@type": "owl:Class",
      "rdfs:label": "Synaptic Noise",
      "rdfs:comment": "Synaptic noise arises from stochastic vesicle release, variable receptor activation, and fluctuations in numbers of available postsynaptic receptors. Synaptic noise contributes to trial-to-trial variability in neural responses and can improve signal detection through stochastic resonance. Background synaptic noise keeps neurons in a high-conductance state that affects integration time and coincidence detection."
    },
    {
      "@id": "ns:CoincidenceDetection",
      "@type": "owl:Class",
      "rdfs:label": "Coincidence Detection",
      "rdfs:comment": "Coincidence detection is sensitive detection of simultaneous or near-simultaneous inputs from multiple sources. Neurons act as coincidence detectors when they have short integration time constants relative to synaptic time scales. Coincidence detection is crucial for sound localization via interaural time differences, temporal coding schemes, and binding of distributed features."
    },
    {
      "@id": "ns:PatternSeparation",
      "@type": "owl:Class",
      "rdfs:label": "Pattern Separation",
      "rdfs:comment": "Pattern separation orthogonalizes similar input patterns to reduce interference in memory storage and enable discrimination of similar experiences. The dentate gyrus implements pattern separation through sparse firing and competitive dynamics. Pattern separation is complementary to pattern completion and both are essential for episodic memory function."
    },
    {
      "@id": "ns:PatternCompletion",
      "@type": "owl:Class",
      "rdfs:label": "Pattern Completion",
      "rdfs:comment": "Pattern completion retrieves complete stored patterns from partial or noisy cues through attractor dynamics. CA3 autoassociative network implements pattern completion allowing memory recall from fragments. Pattern completion trades off with pattern separation, requiring the network to balance storage capacity with retrieval from partial cues and discrimination of similar patterns."
    },
    {
      "@id": "ns:OptimalControl",
      "@type": "owl:Class",
      "rdfs:label": "Optimal Control",
      "rdfs:comment": "Optimal control theory finds control policies that minimize cost functions subject to system dynamics. In motor control, optimal control explains smooth trajectories, coordination, and adaptation by minimizing combinations of energy, effort, endpoint variance, and trajectory deviation. Neural implementations may use forward models, state estimation, and feedback control."
    },
    {
      "@id": "ns:ForwardModel",
      "@type": "owl:Class",
      "rdfs:label": "Forward Model",
      "rdfs:comment": "A forward model predicts sensory consequences of motor commands, enabling feedforward control without sensory feedback delays. Forward models in cerebellum and parietal cortex predict arm position, eye position, and other state variables. They enable motor planning, state estimation, cancellation of self-generated sensory signals, and compensation for feedback delays."
    },
    {
      "@id": "ns:InverseModel",
      "@type": "owl:Class",
      "rdfs:label": "Inverse Model",
      "rdfs:comment": "An inverse model computes motor commands needed to achieve desired movements or reach target states. Inverse models solve the ill-posed inverse problem of determining joint torques or muscle activations from desired kinematics. They may be learned through motor babbling and error-driven learning and implemented in motor cortex and cerebellum."
    },
    {
      "@id": "ns:BayesianInference",
      "@type": "owl:Class",
      "rdfs:label": "Bayesian Inference",
      "rdfs:comment": "Bayesian inference combines sensory likelihood with prior expectations to estimate world states and make decisions under uncertainty. Neural implementations may encode probability distributions through population codes and implement optimal cue combination, multisensory integration, and perceptual inference. Bayesian frameworks explain many perceptual and motor phenomena as optimal inference."
    },
    {
      "@id": "ns:DecisionMaking",
      "@type": "owl:Class",
      "rdfs:label": "Decision Making",
      "rdfs:comment": "Decision making selects actions based on available information, goals, and expected outcomes. Neural correlates include ramping activity in parietal and prefrontal cortex accumulating evidence to threshold. Models include drift-diffusion, race models, and attractor networks with competing populations. Decisions optimize speed-accuracy tradeoffs and incorporate prior probabilities and value."
    },
    {
      "@id": "ns:RewardPrediction",
      "@type": "owl:Class",
      "rdfs:label": "Reward Prediction",
      "rdfs:comment": "Reward prediction estimates expected future rewards based on current state and potential actions. Dopamine neurons signal reward prediction errors - the difference between received and predicted reward. These error signals drive reinforcement learning, updating value estimates and policies. Temporal difference learning models account for phasic dopamine responses and value learning."
    },
    {
      "@id": "ns:ReinforcementLearning",
      "@type": "owl:Class",
      "rdfs:label": "Reinforcement Learning",
      "rdfs:comment": "Reinforcement learning learns actions that maximize cumulative reward through trial-and-error. Algorithms include temporal difference learning, Q-learning, and policy gradient methods. Dopamine implements reward prediction error signals. Basal ganglia and prefrontal cortex represent state-action values and policies. Reinforcement learning explains habit formation, skill learning, and adaptive behavior."
    },
    {
      "@id": "ns:TemporalDifferenceLearning",
      "@type": "owl:Class",
      "rdfs:label": "Temporal Difference Learning",
      "rdfs:comment": "Temporal difference learning updates value estimates based on differences between successive predictions, bootstrapping from future estimates. TD errors match dopamine neuron responses in timing and to reward manipulations. TD learning enables credit assignment over time without requiring terminal rewards, explaining how animals learn to predict rewards from early predictive cues.",
      "rdfs:subClassOf": {
        "@id": "ns:ReinforcementLearning"
      }
    },
    {
      "@id": "ns:EmotionalProcessing",
      "@type": "owl:Class",
      "rdfs:label": "Emotional Processing",
      "rdfs:comment": "Emotional processing evaluates the affective significance of stimuli as rewarding or punishing and triggers appropriate responses. The amygdala and orbitofrontal cortex learn associations between stimuli and primary reinforcers through pattern association. Emotional states bias perception, memory, and decision making and are mediated by projections from emotional to sensory and cognitive areas."
    },
    {
      "@id": "ns:AttentionMechanism",
      "@type": "owl:Class",
      "rdfs:label": "Attention Mechanism",
      "rdfs:comment": "Attention selectively enhances processing of relevant stimuli while filtering distractors. Mechanisms include increased gain, reduced noise correlations, synchronized oscillations, and competitive interactions. Top-down attention from prefrontal and parietal cortex modulates sensory processing via feedback connections. Bottom-up attention is driven by stimulus salience. Attention enhances encoding, speeds processing, and improves discrimination."
    },
    {
      "@id": "ns:VisualAttention",
      "@type": "owl:Class",
      "rdfs:label": "Visual Attention",
      "rdfs:comment": "Visual attention enhances processing at attended locations or features through modulation of activity in visual cortex. Spatial attention shifts the attentional spotlight to locations while feature attention selects objects or features. Attention effects include enhanced firing rates, reduced response latencies, sharper tuning, and improved signal-to-noise. Attention is necessary for visual awareness and binding of features.",
      "rdfs:subClassOf": {
        "@id": "ns:AttentionMechanism"
      }
    },
    {
      "@id": "ns:SaliencyMap",
      "@type": "owl:Class",
      "rdfs:label": "Saliency Map",
      "rdfs:comment": "A saliency map represents bottom-up stimulus-driven attention by combining feature contrasts across multiple dimensions like color, intensity, and orientation. Locations with high saliency attract attention and gaze. Saliency maps are computed by center-surround mechanisms and winner-take-all competition. Superior colliculus and lateral intraparietal area may implement saliency representations for orienting.",
      "rdfs:subClassOf": {
        "@id": "ns:AttentionMechanism"
      }
    },
    {
      "@id": "ns:hasChannel",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "has channel",
      "rdfs:comment": "This property relates a neuron to the ion channels expressed in its membrane. Different neurons express different complements of channels determining their intrinsic excitability, firing patterns, and responses to inputs. Channel expression can vary across subcellular compartments and can be modulated by activity and neuromodulators.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:IonChannel"
      }
    },
    {
      "@id": "ns:formsSynapseWith",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "forms synapse with",
      "rdfs:comment": "This property represents synaptic connectivity between neurons. The domain neuron is presynaptic and the range neuron is postsynaptic. Connection patterns determine network function, with different connectivity motifs implementing different computations. Synaptic connections are modified by learning and development.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:locatedIn",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "located in",
      "rdfs:comment": "This property specifies the brain region or anatomical location where a neuron or structure is found. Location constrains connectivity and function, as neurons can only form connections with other neurons in connected regions. Different regions implement different computations based on their connectivity and cellular composition.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Hippocampus"
      }
    },
    {
      "@id": "ns:releases",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "releases",
      "rdfs:comment": "This property relates a neuron to the neurotransmitter it releases at its synaptic terminals. Most neurons release one primary fast neurotransmitter (glutamate or GABA) but may also release neuromodulators or neuropeptides. The transmitter determines whether synapses are excitatory or inhibitory and what receptors mediate the response.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neurotransmitter"
      }
    },
    {
      "@id": "ns:bindsTo",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "binds to",
      "rdfs:comment": "This property relates a neurotransmitter to the receptors it activates. Neurotransmitters typically act on multiple receptor subtypes with different kinetics, ion selectivity, and downstream signaling. The receptor determines the sign and time course of postsynaptic responses and can gate ion channels or trigger second messenger cascades.",
      "rdfs:domain": {
        "@id": "ns:Neurotransmitter"
      },
      "rdfs:range": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:modulatesActivityOf",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "modulates activity of",
      "rdfs:comment": "This property represents modulatory influences on neural activity such as neuromodulation, attention, or arousal. Modulation alters gain, excitability, plasticity, or other neural properties without directly driving firing. Modulatory signals typically act over longer timescales than direct synaptic transmission and can affect many neurons or entire networks.",
      "rdfs:domain": {
        "@id": "ns:Neurotransmitter"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:implementsComputation",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "implements computation",
      "rdfs:comment": "This property relates neural circuits or brain regions to the computations they perform. Examples include pattern separation in dentate gyrus, pattern completion in CA3, and optimal cue combination in multisensory areas. Understanding neural computation requires linking circuit properties to algorithmic function and behavioral performance.",
      "rdfs:domain": {
        "@id": "ns:NeuralNetwork"
      },
      "rdfs:range": {
        "@id": "ns:PatternSeparation"
      }
    },
    {
      "@id": "ns:projectsTo",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "projects to",
      "rdfs:comment": "This property represents axonal projections between brain regions forming anatomical pathways. Projections can be feedforward, feedback, or lateral and may be topographically organized. The pattern of projections determines information flow through the brain and enables hierarchical processing, coordination across areas, and integration of multiple information sources.",
      "rdfs:domain": {
        "@id": "ns:Hippocampus"
      },
      "rdfs:range": {
        "@id": "ns:PrefrontalCortex"
      }
    },
    {
      "@id": "ns:exhibitsPlasticity",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "exhibits plasticity",
      "rdfs:comment": "This property relates synapses or neural structures to the forms of plasticity they exhibit. Different synapses show different forms of plasticity with different induction requirements, expression mechanisms, and time courses. Plasticity rules determine what associations can be learned and how experience modifies neural circuits.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "ns:SynapticPlasticity"
      }
    },
    {
      "@id": "ns:generatesSignal",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "generates signal",
      "rdfs:comment": "This property relates neurons to the electrical signals they produce. Signals include action potentials, graded potentials, and local dendritic spikes. The type and pattern of signals depends on membrane properties, morphology, and input patterns. Signal properties determine information transmission, reliability, and coding strategies.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:ActionPotential"
      }
    },
    {
      "@id": "ns:encodes",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "encodes",
      "rdfs:comment": "This property relates neural activity to the information it represents about stimuli, actions, or internal states. Encoding can use rate codes, temporal codes, or population codes. Understanding what variables neurons encode and how is central to understanding neural computation and linking neural activity to perception and behavior.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:NeuralCode"
      }
    },
    {
      "@id": "ns:controlsMovement",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "controls movement",
      "rdfs:comment": "This property relates motor control structures to the movements they control. Motor control involves planning, initiation, execution, and online correction of movements. Different brain regions control different aspects with motor cortex specifying movement parameters, basal ganglia selecting actions, and cerebellum enabling learning and coordination.",
      "rdfs:domain": {
        "@id": "ns:MotorCortex"
      },
      "rdfs:range": {
        "@id": "ns:OptimalControl"
      }
    },
    {
      "@id": "ns:processesInformation",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "processes information",
      "rdfs:comment": "This property relates brain regions to the type of information they process. Information types include sensory modalities (vision, audition), cognitive variables (working memory, value), and motor commands. Understanding what information different regions process and how it is transformed is key to understanding brain organization and function.",
      "rdfs:domain": {
        "@id": "ns:VisualCortex"
      },
      "rdfs:range": {
        "@id": "ns:SensoryProcessing"
      }
    },
    {
      "@id": "ns:learns",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "learns",
      "rdfs:comment": "This property relates neural systems to what they learn and the learning rules used. Different regions learn different associations - hippocampus learns episodic associations, cerebellum learns sensorimotor associations, and cortex learns statistical regularities. Learning mechanisms include Hebbian plasticity, error-driven learning, and reinforcement learning.",
      "rdfs:domain": {
        "@id": "ns:Hippocampus"
      },
      "rdfs:range": {
        "@id": "ns:EpisodicMemory"
      }
    },
    {
      "@id": "ns:integratesInput",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "integrates input",
      "rdfs:comment": "This property relates neurons or dendrites to how they integrate multiple inputs. Integration can be linear summation, sublinear due to shunting inhibition, or supralinear due to dendritic spikes or NMDA receptors. Integration mode affects neuronal computation, determining whether neurons act as linear filters, coincidence detectors, or nonlinear processors.",
      "rdfs:domain": {
        "@id": "ns:Dendrite"
      },
      "rdfs:range": {
        "@id": "ns:Synapse"
      }
    },
    {
      "@id": "ns:hasMembranePotential",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has membrane potential",
      "rdfs:comment": "This property represents the membrane potential value of a neuron in millivolts. Resting potential is typically around -70mV, with action potentials reaching +40mV. Membrane potential determines channel open probabilities, synaptic drive, and proximity to spike threshold. It reflects the balance of ionic currents across the membrane.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasFiringRate",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has firing rate",
      "rdfs:comment": "This property specifies the average firing rate of a neuron in spikes per second (Hz). Firing rates vary from spontaneous rates of 1-10 Hz to maximum rates exceeding 100 Hz. Firing rate encodes stimulus intensity, behavioral variables, and is a key measure of neural activity used in rate coding schemes.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasTimeConstant",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has time constant",
      "rdfs:comment": "This property specifies the membrane time constant in milliseconds, determining how fast membrane potential changes in response to inputs. Time constants range from 10-50ms depending on membrane resistance and capacitance. Shorter time constants enable faster responses and better temporal precision while longer time constants provide more integration of inputs.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasSynapticWeight",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has synaptic weight",
      "rdfs:comment": "This property represents the strength of a synaptic connection as a scalar weight determining the amplitude of postsynaptic responses. Weights are modified by learning and determine the influence of presynaptic activity on postsynaptic firing. Weight distributions and dynamics are crucial for network computation, memory capacity, and stability.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasDelay",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has delay",
      "rdfs:comment": "This property specifies the conduction and synaptic delay in milliseconds between presynaptic spike and postsynaptic response. Delays depend on axon length, myelination, and synaptic transmission time. Delays affect temporal coding, synchronization, and can be exploited for motion detection and coincidence detection with properly delayed signals.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasChannelDensity",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has channel density",
      "rdfs:comment": "This property specifies the density of ion channels per square micrometer of membrane. Channel densities vary across cell types and subcellular locations from less than 1 to hundreds per square micrometer. High sodium channel density at the axon initial segment enables spike initiation. Channel density determines excitability, spike shape, and integration properties.",
      "rdfs:domain": {
        "@id": "ns:IonChannel"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasCapacity",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has capacity",
      "rdfs:comment": "This property represents the storage capacity of a memory system measured in number of patterns or bits. Capacity depends on network size, connectivity, coding sparseness, and interference between patterns. Autoassociative networks have capacity proportional to number of connections per neuron. Understanding capacity limits is crucial for memory models.",
      "rdfs:domain": {
        "@id": "ns:AttractorNetwork"
      },
      "rdfs:range": {
        "@id": "xsd:integer"
      }
    },
    {
      "@id": "ns:hasLatency",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has latency",
      "rdfs:comment": "This property specifies response latency in milliseconds from stimulus onset to neural response. Latencies reflect processing time through hierarchical pathways. Early sensory areas have short latencies (50-100ms) while higher areas have longer latencies (100-200ms). Latency provides information about processing stage and can encode stimulus properties.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasReliability",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has reliability",
      "rdfs:comment": "This property quantifies reliability of neural responses or synaptic transmission as a probability or correlation measure. Reliability varies from highly reliable (correlation >0.9) in sensory neurons to unreliable (correlation <0.3) in cortex. Reliability affects information transmission and determines whether responses can support precise temporal coding.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasPrecision",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has precision",
      "rdfs:comment": "This property specifies temporal precision of spike timing in milliseconds measured as jitter across trials. Precision ranges from sub-millisecond in auditory brainstem to tens of milliseconds in cortex. High precision enables temporal coding and coincidence detection but requires precise inputs and appropriate membrane time constants.",
      "rdfs:domain": {
        "@id": "ns:ActionPotential"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasBandwidth",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has bandwidth",
      "rdfs:comment": "This property represents the frequency range or bandwidth in Hz over which a neuron or system can respond or transmit information. Bandwidth is limited by membrane time constants, synaptic kinetics, and refractory periods. Higher bandwidth enables faster temporal processing and response to rapid stimulus changes.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasAmplitude",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has amplitude",
      "rdfs:comment": "This property specifies the amplitude of neural signals in millivolts. Action potential amplitude is typically 80-100mV while synaptic potentials range from <1mV to tens of mV. Amplitude determines signal detectability, propagation reliability, and influences downstream neurons. Amplitude can be modulated by channel expression and previous activity.",
      "rdfs:domain": {
        "@id": "ns:ActionPotential"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasThreshold",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has threshold",
      "rdfs:comment": "This property represents the membrane potential threshold for action potential initiation in millivolts, typically around -50 to -40mV. Threshold depends on sodium channel density and kinetics, varies dynamically with previous activity, and determines the input-output gain. Threshold variability contributes to firing reliability and stochastic spiking.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasLearningRate",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has learning rate",
      "rdfs:comment": "This property specifies the learning rate parameter determining how fast synaptic weights change with experience. Learning rates must be small enough for stable learning but large enough for reasonable convergence time. Optimal learning rates depend on network size, task complexity, and noise levels. Learning rates may be adaptive or context-dependent.",
      "rdfs:domain": {
        "@id": "ns:LearningRule"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasInformationRate",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has information rate",
      "rdfs:comment": "This property quantifies the rate of information transmission in bits per second. Information rates depend on firing rates, temporal precision, and noise correlations. Single neurons typically transmit 1-3 bits per spike. Population codes can achieve higher rates through parallel channels. Information rate measures coding efficiency.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:Backpropagation",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Backpropagation",
      "rdfs:comment": "Backpropagation is an error-driven supervised learning algorithm that propagates errors from output to hidden layers to update connection weights. While influential in machine learning, evidence for biological backpropagation is limited. Possible neural implementations include feedback connections, dendritic processing, and neuromodulatory signals. Backpropagation enables learning of internal representations in multilayer networks."
    },
    {
      "@id": "ns:Perceptron",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuronalModel"
      ],
      "rdfs:label": "Perceptron",
      "rdfs:comment": "The perceptron is a simple feedforward neural network model with linear weighted summation followed by a threshold nonlinearity. It can learn linearly separable classifications through error-driven weight updates. Though limited, the perceptron established foundational concepts including synaptic plasticity rules and the idea that networks could learn from examples."
    },
    {
      "@id": "ns:DeltaRule",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Delta Rule",
      "rdfs:comment": "The delta rule is a supervised learning algorithm that adjusts weights proportional to the error between actual and desired outputs. It minimizes error through gradient descent and is equivalent to the Widrow-Hoff rule. The delta rule enables learning of continuous input-output mappings and is fundamental to many neural network learning algorithms."
    },
    {
      "@id": "ns:BCMRule",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "BCM Rule",
      "rdfs:comment": "The BCM (Bienenstock-Cooper-Munro) learning rule is a rate-based plasticity rule with a sliding modification threshold that depends on postsynaptic activity. BCM produces stable competitive learning with selective enhancement of correlated inputs. It explains development of orientation selectivity and implements both LTP and LTD based on postsynaptic activity levels."
    },
    {
      "@id": "ns:HopfieldNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:AttractorNetwork"
      ],
      "rdfs:label": "Hopfield Network",
      "rdfs:comment": "The Hopfield network is a recurrent autoassociative network that stores patterns as stable attractor states through symmetric connections. It performs pattern completion and can serve as content-addressable memory. The network dynamics minimize an energy function with stored patterns as local minima. Hopfield networks demonstrated that recurrent networks could implement memory and influenced theories of hippocampal function."
    },
    {
      "@id": "ns:BoltzmannMachine",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralNetwork"
      ],
      "rdfs:label": "Boltzmann Machine",
      "rdfs:comment": "The Boltzmann machine is a stochastic recurrent network with symmetric weights that implements probabilistic inference. It learns probability distributions over input patterns and can generate samples from learned distributions. Restricted Boltzmann machines with layered architecture enable efficient learning. Boltzmann machines connect neural networks to statistical mechanics and probabilistic models."
    },
    {
      "@id": "ns:SOMNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralNetwork"
      ],
      "rdfs:label": "Self-Organizing Map",
      "rdfs:comment": "Self-organizing maps (Kohonen networks) form topographic representations of input spaces through unsupervised competitive learning with neighborhood cooperation. They create low-dimensional representations preserving topological relationships in high-dimensional input spaces. SOMs model development of cortical maps including orientation columns, ocular dominance columns, and somatotopic maps."
    },
    {
      "@id": "ns:GramicidinChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:IonChannel"
      ],
      "rdfs:label": "Gramicidin Channel",
      "rdfs:comment": "Gramicidin A is a peptide that forms ion channels in membranes through head-to-head dimerization. It has been extensively studied through molecular dynamics simulations and electrostatic calculations. Gramicidin serves as a model system for understanding ion permeation, selectivity mechanisms, and the behavior of ions in confined geometries. It selectively conducts monovalent cations."
    },
    {
      "@id": "ns:KcsAChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:PotassiumChannel"
      ],
      "rdfs:label": "KcsA Channel",
      "rdfs:comment": "KcsA is a bacterial potassium channel whose crystal structure revealed the molecular basis of ion selectivity. The selectivity filter has the signature TVGYG motif conserved across potassium channels. KcsA demonstrates how carbonyl oxygens can substitute for water molecules in the hydration shell of potassium while excluding smaller sodium ions. It has been extensively studied through simulations and experiments."
    },
    {
      "@id": "ns:NaVChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:SodiumChannel"
      ],
      "rdfs:label": "Voltage-Gated Sodium Channel",
      "rdfs:comment": "Voltage-gated sodium channels (NaV) are responsible for action potential upstroke through rapid activation and inactivation. They have four homologous domains each with six transmembrane segments including a voltage sensor. Multiple subtypes exist with different kinetics and distributions. Mutations cause channelopathies including epilepsy and cardiac arrhythmias. They are targets for local anesthetics and anticonvulsants."
    },
    {
      "@id": "ns:DelayedRectifier",
      "@type": [
        "owl:NamedIndividual",
        "ns:PotassiumChannel"
      ],
      "rdfs:label": "Delayed Rectifier Potassium Channel",
      "rdfs:comment": "Delayed rectifier potassium channels activate with delay following depolarization and mediate action potential repolarization. They show little or no inactivation, allowing sustained outward current. Delayed rectifiers include Kv2 and Kv3 families with different voltage dependences and kinetics. They regulate action potential width, firing frequency, and prevent excessive depolarization."
    },
    {
      "@id": "ns:ATypeChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:PotassiumChannel"
      ],
      "rdfs:label": "A-Type Potassium Channel",
      "rdfs:comment": "A-type potassium channels activate rapidly at subthreshold voltages and inactivate quickly. They regulate excitability, delay firing to first spike, and shape dendritic integration. A-channels are enriched in dendrites where they influence backpropagation of action potentials and reduce temporal summation. They contribute to diverse firing patterns and regulate spike timing."
    },
    {
      "@id": "ns:SKChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:PotassiumChannel"
      ],
      "rdfs:label": "SK Channel",
      "rdfs:comment": "Small conductance calcium-activated potassium channels (SK channels) are activated by intracellular calcium with no voltage dependence. They mediate afterhyperpolarizations following spikes, regulate firing frequency, and contribute to spike frequency adaptation. SK channels link calcium dynamics to membrane potential and are modulated by neuromodulators and phosphorylation."
    },
    {
      "@id": "ns:BKChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:PotassiumChannel"
      ],
      "rdfs:label": "BK Channel",
      "rdfs:comment": "Big conductance calcium and voltage-activated potassium channels (BK or Maxi-K) have large single channel conductance and are activated by both voltage and calcium. They are activated during action potentials through calcium entry and voltage changes. BK channels regulate action potential width, enable high-frequency firing, and couple calcium dynamics to electrical activity."
    },
    {
      "@id": "ns:LTypeCalciumChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumChannel"
      ],
      "rdfs:label": "L-Type Calcium Channel",
      "rdfs:comment": "L-type calcium channels activate at relatively depolarized potentials, have large single channel conductance, and show little inactivation. They contribute to plateau potentials, calcium-dependent processes, and dendritic integration. L-channels couple membrane activity to gene expression and plasticity through calcium signaling to the nucleus. They are blocked by dihydropyridines."
    },
    {
      "@id": "ns:TTypeCalciumChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumChannel"
      ],
      "rdfs:label": "T-Type Calcium Channel",
      "rdfs:comment": "T-type calcium channels activate at relatively hyperpolarized potentials, have small conductance, and inactivate rapidly. They mediate low-threshold spikes and contribute to burst firing, oscillations, and pacemaking. T-channels are important for thalamocortical oscillations and are modulated by neurotransmitters and voltage history."
    },
    {
      "@id": "ns:NTypeCalciumChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumChannel"
      ],
      "rdfs:label": "N-Type Calcium Channel",
      "rdfs:comment": "N-type calcium channels are primarily localized to presynaptic terminals where they mediate neurotransmitter release. They activate rapidly at moderate depolarizations and are modulated by G-proteins. N-channels are blocked by omega-conotoxin and are targets for pain medications. They couple action potentials to calcium-triggered vesicle fusion."
    },
    {
      "@id": "ns:PQTypeCalciumChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumChannel"
      ],
      "rdfs:label": "P/Q-Type Calcium Channel",
      "rdfs:comment": "P/Q-type calcium channels mediate neurotransmitter release at many synapses and contribute to dendritic calcium signals. Mutations cause familial hemiplegic migraine and episodic ataxia. They are blocked by omega-agatoxin. P/Q channels couple action potentials to transmitter release with high efficiency and are modulated by calcium-binding proteins."
    },
    {
      "@id": "ns:HCNChannel",
      "@type": [
        "owl:NamedIndividual",
        "ns:IonChannel"
      ],
      "rdfs:label": "HCN Channel",
      "rdfs:comment": "Hyperpolarization-activated cyclic nucleotide-gated (HCN) channels conduct mixed sodium and potassium current activated by hyperpolarization. They mediate the Ih current contributing to resting potential, rhythmic firing, and dendritic integration. HCN channels are modulated by cAMP and contribute to synaptic integration, rebound firing, and resonance properties."
    },
    {
      "@id": "ns:Acetylcholine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Acetylcholine",
      "rdfs:comment": "Acetylcholine is a neurotransmitter acting at nicotinic (ionotropic) and muscarinic (metabotropic) receptors. It mediates neuromuscular transmission, autonomic functions, and neuromodulation in the brain. Cholinergic modulation enhances attention, arousal, and plasticity. Acetylcholine is implicated in Alzheimer's disease with degeneration of cholinergic neurons. It is synthesized by choline acetyltransferase."
    },
    {
      "@id": "ns:Dopamine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Dopamine",
      "rdfs:comment": "Dopamine is a catecholamine neurotransmitter acting through metabotropic D1-D5 receptors. It modulates motor control, reward learning, motivation, and cognition. Dopamine neurons show phasic responses encoding reward prediction errors used in reinforcement learning. Dopamine dysfunction underlies Parkinson's disease, schizophrenia, and addiction. Different pathways have distinct functions including nigrostriatal and mesolimbic systems."
    },
    {
      "@id": "ns:Serotonin",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Serotonin",
      "rdfs:comment": "Serotonin (5-HT) acts through multiple receptor subtypes including both ionotropic (5-HT3) and metabotropic receptors. It modulates mood, sleep, appetite, and various cognitive functions. Serotonergic neurons in raphe nuclei project widely throughout the brain. Serotonin is implicated in depression and anxiety and is targeted by SSRIs and other psychoactive drugs."
    },
    {
      "@id": "ns:Norepinephrine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Norepinephrine",
      "rdfs:comment": "Norepinephrine (noradrenaline) is a catecholamine acting through alpha and beta adrenergic receptors. It enhances arousal, attention, and stress responses. Noradrenergic neurons in locus coeruleus have widespread projections. Norepinephrine modulates synaptic plasticity, sensory processing, and network state. It is involved in attention deficit disorder and depression."
    },
    {
      "@id": "ns:Histamine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Histamine",
      "rdfs:comment": "Histamine acts as a neurotransmitter through H1-H4 metabotropic receptors. Histaminergic neurons in tuberomammillary nucleus promote wakefulness and arousal. Histamine modulates attention, learning, and inflammation. Antihistamines cause drowsiness by blocking histamine receptors. Histamine also regulates feeding, circadian rhythms, and stress responses through hypothalamic circuits."
    },
    {
      "@id": "ns:Glycine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Glycine",
      "rdfs:comment": "Glycine is the major inhibitory neurotransmitter in the spinal cord and brainstem, acting through ionotropic glycine receptors permeable to chloride. It mediates fast inhibition in motor control circuits and sensory pathways. Glycine is also a co-agonist at NMDA receptors where it is required for channel opening. Glycine receptor mutations cause hyperekplexia (startle disease)."
    },
    {
      "@id": "ns:LIFNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:IntegrateAndFireModel"
      ],
      "rdfs:label": "Leaky Integrate-and-Fire Neuron",
      "rdfs:comment": "The leaky integrate-and-fire (LIF) neuron is the most common integrate-and-fire model including leak current. Membrane potential decays toward rest with time constant tau in absence of input. LIF neurons capture essential features of neural integration including threshold dynamics, refractoriness, and temporal filtering while remaining analytically tractable. They are widely used in large-scale network simulations."
    },
    {
      "@id": "ns:IzhikevichNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuronalModel"
      ],
      "rdfs:label": "Izhikevich Neuron",
      "rdfs:comment": "The Izhikevich model is a two-dimensional model that reproduces many firing patterns seen in real neurons including regular spiking, fast spiking, bursting, and chattering. It has computational efficiency comparable to integrate-and-fire models while capturing rich dynamics of conductance-based models. Parameters can be tuned to match different neuron types. The model is widely used for large-scale simulations."
    },
    {
      "@id": "ns:AdaptiveExponentialIF",
      "@type": [
        "owl:NamedIndividual",
        "ns:IntegrateAndFireModel"
      ],
      "rdfs:label": "Adaptive Exponential Integrate-and-Fire",
      "rdfs:comment": "The adaptive exponential integrate-and-fire (AdEx) model includes an exponential spike-generating current and an adaptation variable. It captures spike-frequency adaptation, bursting, and irregular spiking while remaining two-dimensional. AdEx closely matches responses of cortical neurons to current injection. It provides a good balance between biological realism and computational efficiency for network simulations."
    },
    {
      "@id": "ns:MorrisLecarModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuronalModel"
      ],
      "rdfs:label": "Morris-Lecar Model",
      "rdfs:comment": "The Morris-Lecar model is a two-dimensional model of barnacle muscle fiber excitability with voltage-gated calcium and potassium channels. It exhibits limit cycle oscillations and serves as a canonical model for studying excitability and bifurcations. Despite its simplicity, it captures essential excitability dynamics and has been analyzed extensively using dynamical systems theory."
    },
    {
      "@id": "ns:ConnorStevensModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuronalModel"
      ],
      "rdfs:label": "Connor-Stevens Model",
      "rdfs:comment": "The Connor-Stevens model extends the Hodgkin-Huxley model by adding an A-type potassium current. This addition captures spike frequency adaptation and reproduces delayed firing to first spike seen in many neurons. The model helped establish how different ion channels contribute to diverse firing patterns and demonstrated that variations in channel composition explain neuronal diversity."
    },
    {
      "@id": "ns:TraubModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuronalModel"
      ],
      "rdfs:label": "Traub Model",
      "rdfs:comment": "Traub models are detailed multi-compartment conductance-based models of hippocampal neurons with many ion channel types. They reproduce diverse firing patterns, dendritic spikes, and calcium dynamics. Traub models have been used to study network oscillations, epileptiform activity, and synaptic integration. They demonstrate how detailed biophysical properties influence network-level phenomena."
    },
    {
      "@id": "ns:OjaRule",
      "@type": [
        "owl:NamedIndividual",
        "ns:HebbianLearning"
      ],
      "rdfs:label": "Oja's Rule",
      "rdfs:comment": "Oja's rule is a normalized Hebbian learning rule that prevents unlimited weight growth through weight-dependent decay. It performs principal component analysis, extracting the direction of maximum variance in input patterns. Oja's rule demonstrates how local learning rules can implement sophisticated statistical computations. It is used in models of development, unsupervised learning, and dimensionality reduction."
    },
    {
      "@id": "ns:CovarianceRule",
      "@type": [
        "owl:NamedIndividual",
        "ns:HebbianLearning"
      ],
      "rdfs:label": "Covariance Rule",
      "rdfs:comment": "The covariance rule modifies synapses based on the product of deviations of pre- and postsynaptic activity from their means. This implements correlation-based learning without the instability of basic Hebbian rules. The covariance rule can account for both LTP and LTD depending on correlation sign and has been proposed to underlie certain forms of synaptic plasticity."
    },
    {
      "@id": "ns:VisNet",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralNetwork"
      ],
      "rdfs:label": "VisNet",
      "rdfs:comment": "VisNet is a hierarchical neural network model of invariant object recognition in the ventral visual stream. It uses trace learning rules that capture temporal continuity of object views during natural viewing. Through hierarchical processing with increasing receptive field sizes, VisNet learns translation, size, view, and other invariances. The model accounts for the development of invariant representations in inferior temporal cortex."
    },
    {
      "@id": "ns:NEFModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralNetwork"
      ],
      "rdfs:label": "Neural Engineering Framework",
      "rdfs:comment": "The Neural Engineering Framework (NEF) provides principles for implementing computations in biologically realistic spiking neural networks. It uses population representation of vectors, weighted connections to implement linear transformations, and nonlinear neuronal responses for nonlinear operations. NEF has been used to build large-scale brain models including SPAUN which performs cognitive tasks using 2.5 million neurons."
    },
    {
      "@id": "ns:LiquidStateMachine",
      "@type": [
        "owl:NamedIndividual",
        "ns:RecurrentNetwork"
      ],
      "rdfs:label": "Liquid State Machine",
      "rdfs:comment": "Liquid state machines process temporal inputs using recurrent networks with fixed random connections (the liquid) followed by trainable readout neurons. The recurrent network maps input histories to high-dimensional state spaces where temporal patterns become separable. This reservoir computing approach demonstrates that random recurrent networks with appropriate dynamics can implement powerful temporal processing with simple learning in readout layers."
    },
    {
      "@id": "ns:EchoStateNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:RecurrentNetwork"
      ],
      "rdfs:label": "Echo State Network",
      "rdfs:comment": "Echo state networks are recurrent neural networks with fixed random recurrent connections and trainable linear readout. They exploit the echo state property where network state depends on recent input history. ESNs can learn complex temporal dynamics and generate sequences. They demonstrate that sophisticated temporal processing emerges from random recurrent dynamics with appropriate time scales and connectivity."
    },
    {
      "@id": "ns:WilsonCowanModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralNetwork"
      ],
      "rdfs:label": "Wilson-Cowan Model",
      "rdfs:comment": "The Wilson-Cowan model describes dynamics of interacting excitatory and inhibitory populations through mean field equations. It captures population-level dynamics including oscillations, bistability, and traveling waves. The model has been used to study cortical dynamics, visual processing, working memory, and decision making. It bridges single neuron models and large-scale brain dynamics."
    },
    {
      "@id": "ns:BindingProblem",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralCode"
      ],
      "rdfs:comment": "The binding problem refers to how features processed in different brain areas are integrated into unified object representations. Proposed solutions include temporal synchrony binding features through correlated firing, attention selecting object features, and hierarchical processing where higher areas integrate features. The binding problem remains fundamental to understanding perceptual integration and conscious experience.",
      "rdfs:label": "Binding Problem"
    },
    {
      "@id": "ns:GammaOscillation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Oscillation"
      ],
      "rdfs:label": "Gamma Oscillation",
      "rdfs:comment": "Gamma oscillations (30-100 Hz) arise from interactions between excitatory pyramidal cells and fast-spiking inhibitory interneurons. They are enhanced during attention, sensory processing, and memory. Gamma may coordinate neural activity, enable temporal multiplexing, and facilitate plasticity. Abnormal gamma is implicated in schizophrenia and autism. Mechanisms include PING (pyramidal-interneuron gamma) and ING (interneuron gamma)."
    },
    {
      "@id": "ns:ThetaOscillation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Oscillation"
      ],
      "rdfs:label": "Theta Oscillation",
      "rdfs:comment": "Theta oscillations (4-8 Hz) are prominent in hippocampus during exploration and REM sleep. Theta organizes spike timing of place cells in sequences representing spatial trajectories. Phase precession relates spike timing to theta phase. Theta coordinates activity across hippocampal subregions and mediates communication with cortex. It is implicated in memory encoding, spatial navigation, and sequential processing."
    },
    {
      "@id": "ns:AlphaOscillation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Oscillation"
      ],
      "rdfs:label": "Alpha Oscillation",
      "rdfs:comment": "Alpha oscillations (8-12 Hz) are prominent in posterior cortex during eyes-closed rest and reduced during visual processing. Alpha may reflect inhibition of task-irrelevant regions, regulate information flow, or represent an idling state. Posterior alpha is modulated by attention and correlates with perceptual performance. Thalamocortical loops generate alpha through reciprocal excitation and inhibition."
    },
    {
      "@id": "ns:BetaOscillation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Oscillation"
      ],
      "rdfs:label": "Beta Oscillation",
      "rdfs:comment": "Beta oscillations (13-30 Hz) are prominent in motor cortex and basal ganglia. They increase during motor preparation and decrease during movement. Beta may maintain the current motor set, reflect status quo processing, or mediate long-range communication. Excessive beta in Parkinson's disease correlates with bradykinesia. Beta oscillations involve cortico-basal ganglia-thalamo-cortical loops."
    },
    {
      "@id": "ns:SharpWaveRipple",
      "@type": [
        "owl:NamedIndividual",
        "ns:Oscillation"
      ],
      "rdfs:label": "Sharp Wave Ripple",
      "rdfs:comment": "Sharp wave ripples are high-frequency oscillations (150-250 Hz) in hippocampus during rest and sleep, associated with memory consolidation. They involve coordinated replay of place cell sequences representing previous experiences at compressed timescales. Ripples are generated by pyramidal-interneuron interactions in CA1 and are triggered by CA3 sharp waves. They mediate hippocampal-cortical communication for memory consolidation."
    },
    {
      "@id": "ns:ExcitatoryInhibitoryBalance",
      "@type": [
        "owl:NamedIndividual",
        "ns:DynamicalSystem"
      ],
      "rdfs:label": "Excitatory-Inhibitory Balance",
      "rdfs:comment": "Excitatory-inhibitory balance refers to the tight coordination of excitation and inhibition in cortical circuits. Balanced networks operate in a regime where excitatory and inhibitory inputs largely cancel, keeping neurons near threshold in a fluctuation-driven regime. This enables fast responses, maintains irregular firing, and implements gain control. Imbalances may underlie neurological disorders."
    },
    {
      "@id": "ns:BarrelCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Barrel Cortex",
      "rdfs:comment": "Barrel cortex in rodent somatosensory cortex contains discrete modules (barrels) corresponding to individual whiskers. It provides a model system for studying sensory processing, cortical organization, and plasticity. Each barrel receives thalamic input from one whisker and processes tactile information. Barrel cortex exhibits columnar organization, lateral inhibition, and experience-dependent plasticity during development."
    },
    {
      "@id": "ns:OcularDominanceColumn",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Ocular Dominance Column",
      "rdfs:comment": "Ocular dominance columns in primary visual cortex organize neurons according to eye preference. They develop through activity-dependent competition between inputs from the two eyes during critical periods. Models include correlation-based Hebbian learning and BCM rules. Monocular deprivation shifts ocular dominance favoring the open eye, demonstrating experience-dependent cortical plasticity."
    },
    {
      "@id": "ns:OrientationColumn",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Orientation Column",
      "rdfs:comment": "Orientation columns organize V1 neurons by their preferred orientation with smooth progression across cortex forming pinwheel patterns around singularities. Orientation selectivity emerges from convergence of LGN inputs and/or cortical interactions. Models include feedforward convergence, recurrent amplification, and self-organization. Orientation maps exhibit precise geometric properties potentially reflecting optimization principles."
    },
    {
      "@id": "ns:InferiorTemporalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Inferior Temporal Cortex",
      "rdfs:comment": "Inferior temporal cortex is the final stage of the ventral visual stream representing objects invariantly with respect to position, size, and view. IT neurons have large receptive fields covering much of the visual field and selective responses to complex shapes, objects, and faces. IT representations support object recognition and provide input to memory systems including hippocampus and prefrontal cortex."
    },
    {
      "@id": "ns:V1",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Primary Visual Cortex",
      "rdfs:comment": "Primary visual cortex (V1 or striate cortex) is the first cortical area in the visual pathway receiving direct thalamic input from LGN. V1 neurons are selective for oriented edges, spatial frequency, and direction of motion. It has retinotopic organization, ocular dominance columns, and orientation columns. V1 performs edge detection, contrast normalization, and provides input to extrastriate areas."
    },
    {
      "@id": "ns:MT",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Middle Temporal Area",
      "rdfs:comment": "Middle temporal area (MT or V5) is specialized for motion processing with most neurons showing direction selectivity and speed tuning. MT receives input from V1 and projects to parietal cortex and eye movement control areas. MT neurons integrate motion signals over space implementing aperture problem solutions and global motion perception. Microstimulation of MT columns biases motion perception."
    },
    {
      "@id": "ns:DorsolateralPrefrontalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:PrefrontalCortex"
      ],
      "rdfs:label": "Dorsolateral Prefrontal Cortex",
      "rdfs:comment": "Dorsolateral prefrontal cortex (DLPFC) maintains spatial working memory and plans goal-directed behavior. DLPFC neurons show sustained activity during delay periods encoding remembered locations or rules. It implements cognitive control, manipulates working memory contents, and coordinates behavior toward goals. DLPFC damage impairs working memory, planning, and executive functions."
    },
    {
      "@id": "ns:OrbitofrontalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:PrefrontalCortex"
      ],
      "rdfs:label": "Orbitofrontal Cortex",
      "rdfs:comment": "Orbitofrontal cortex represents the value of stimuli and predicted outcomes guiding value-based decision making. OFC neurons encode expected rewards, punishments, and relative value. It receives inputs from sensory cortices and amygdala and projects to striatum and other decision areas. OFC supports rapid reversal learning and flexible value updating. Damage impairs value-based choice and emotion regulation."
    },
    {
      "@id": "ns:AnteriorCingulateCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:PrefrontalCortex"
      ],
      "rdfs:label": "Anterior Cingulate Cortex",
      "rdfs:comment": "Anterior cingulate cortex monitors performance, detects conflicts and errors, and signals when control adjustments are needed. ACC neurons respond to unexpected outcomes, errors, and response conflicts. It evaluates action outcomes and motivational significance. ACC guides learning by signaling when behavioral strategies should change and appears to integrate cognitive and emotional information for adaptive control."
    },
    {
      "@id": "ns:StriatumNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Striatum Neuron",
      "rdfs:comment": "Striatal medium spiny neurons are the principal neurons of the striatum integrating cortical and thalamic inputs. They have extensive dendritic arbors, show bistable membrane potentials, and require convergent inputs to fire. Direct pathway neurons facilitate movement while indirect pathway neurons suppress movement. Striatal plasticity is modulated by dopamine and underlies habit learning and action selection."
    },
    {
      "@id": "ns:SubstantiaNigraDANeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Substantia Nigra Dopamine Neuron",
      "rdfs:comment": "Dopamine neurons in substantia nigra pars compacta project to striatum forming the nigrostriatal pathway. They show phasic responses encoding reward prediction errors - increases for unexpected rewards and decreases for omitted rewards. These teaching signals drive reinforcement learning. Degeneration of these neurons causes Parkinson's disease motor symptoms. They fire tonically at 2-10 Hz and exhibit burst firing to salient stimuli."
    },
    {
      "@id": "ns:VTADANeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "VTA Dopamine Neuron",
      "rdfs:comment": "Dopamine neurons in ventral tegmental area project to prefrontal cortex, nucleus accumbens, and limbic structures forming the mesolimbic and mesocortical pathways. They encode reward prediction errors, motivational salience, and novelty. VTA dopamine is crucial for reward learning, motivation, and addiction. These neurons show heterogeneous properties with some responding to aversive stimuli."
    },
    {
      "@id": "ns:CholinergicBasalForebrain",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Cholinergic Basal Forebrain Neuron",
      "rdfs:comment": "Cholinergic neurons in basal forebrain including nucleus basalis project widely to cortex and hippocampus. They enhance attention, arousal, and cortical plasticity. Cholinergic modulation increases signal-to-noise, sharpens tuning, and enables learning. These neurons are active during waking and REM sleep and degenerate in Alzheimer's disease. They respond to rewards, salient stimuli, and attentional cues."
    },
    {
      "@id": "ns:SerotoninRapheNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Serotonin Raphe Neuron",
      "rdfs:comment": "Serotonergic neurons in raphe nuclei project throughout the brain modulating mood, sleep-wake cycles, and various functions. They fire tonically during waking, decrease during slow-wave sleep, and cease during REM sleep. Serotonin modulates cortical excitability, synaptic plasticity, and sensory processing. These neurons are targets of antidepressants and implicated in mood disorders."
    },
    {
      "@id": "ns:NoradrenergicLocusCoeruleus",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Noradrenergic Locus Coeruleus Neuron",
      "rdfs:comment": "Noradrenergic neurons in locus coeruleus have widespread projections implementing arousal, attention, and stress responses. They show phasic responses to salient or unexpected stimuli and tonic activity related to arousal level. Norepinephrine enhances signal-to-noise, facilitates plasticity, and implements gain control. LC activity follows inverted-U relationship with performance, optimal at moderate arousal."
    },
    {
      "@id": "ns:ThalamocorticalNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Thalamocortical Neuron",
      "rdfs:comment": "Thalamocortical neurons relay sensory information from thalamus to cortex and participate in thalamocortical oscillations. They exhibit two firing modes: tonic mode for faithful relay during waking and burst mode during sleep supporting oscillations. T-type calcium channels mediate burst firing. Thalamocortical loops generate sleep spindles, delta oscillations, and may support attention and consciousness."
    },
    {
      "@id": "ns:ThalamoreticulalNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Interneuron"
      ],
      "rdfs:label": "Thalamic Reticular Neuron",
      "rdfs:comment": "Thalamic reticular nucleus neurons are GABAergic interneurons providing feedforward and feedback inhibition to thalamocortical neurons. They have extensive dendritic arbors, show burst firing, and are interconnected by gap junctions. TRN implements sensory gating, generates spindle oscillations, and may focus attention by inhibiting neurons representing unattended stimuli. TRN forms a shell around dorsal thalamus."
    },
    {
      "@id": "ns:LateralGeniculate",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Lateral Geniculate Nucleus",
      "rdfs:comment": "Lateral geniculate nucleus is the thalamic relay for visual information from retina to V1. It has six layers with magnocellular layers processing motion and parvocellular layers processing color and form. LGN performs gain control, implements surround suppression, and is modulated by attention and cortical feedback. LGN neurons have center-surround receptive fields and maintain retinotopic organization."
    },
    {
      "@id": "ns:SuperiorColliculus",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Superior Colliculus",
      "rdfs:comment": "Superior colliculus controls orienting movements including saccadic eye movements and head movements. It has topographic maps representing space and motor commands. SC integrates multisensory information and salience signals to select targets for orienting. Superficial layers process visual input while deep layers generate motor commands. SC is essential for reflexive orienting and implements spatial attention."
    },
    {
      "@id": "ns:InferiorOlive",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Inferior Olive",
      "rdfs:comment": "Inferior olive provides climbing fiber input to cerebellar Purkinje cells serving as a teaching signal in motor learning. Each Purkinje cell receives input from one climbing fiber producing complex spikes. Climbing fiber activity signals errors between intended and actual movement and drives plasticity of parallel fiber synapses. Inferior olive neurons are coupled by gap junctions producing synchronized oscillations."
    },
    {
      "@id": "ns:DeepCerebellarNuclei",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Deep Cerebellar Nuclei",
      "rdfs:comment": "Deep cerebellar nuclei are the output stage of cerebellum receiving inhibitory input from Purkinje cells and excitatory input from mossy fiber and climbing fiber collaterals. They project to motor cortex via thalamus, brainstem motor centers, and red nucleus. Nuclear neurons integrate Purkinje cell simple spikes encoding learned motor commands with direct mossy and climbing fiber excitation."
    },
    {
      "@id": "ns:RedNucleus",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Red Nucleus",
      "rdfs:comment": "Red nucleus receives input from motor cortex and cerebellum and projects to spinal cord via rubrospinal tract controlling limb movements. In primates, it primarily serves as a relay between cerebellum and motor cortex via thalamus. Red nucleus is involved in motor learning, movement correction, and integrates cortical and cerebellar information for motor control."
    },
    {
      "@id": "ns:BasalGanglia",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Basal Ganglia",
      "rdfs:comment": "Basal ganglia are subcortical nuclei including striatum, globus pallidus, substantia nigra, and subthalamic nucleus that select and reinforce actions. They implement action selection through competing direct and indirect pathways modulated by dopamine. Basal ganglia support reinforcement learning, habit formation, and motivated behavior. Dysfunction causes Parkinson's disease, Huntington's disease, and movement disorders."
    },
    {
      "@id": "ns:EntorhinalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Entorhinal Cortex",
      "rdfs:comment": "Entorhinal cortex is the major input and output structure of the hippocampus containing grid cells, border cells, and object-location cells. Layer II projects to dentate gyrus and CA3 via perforant path, while layer III projects to CA1. Grid cells provide metric information for navigation. Entorhinal cortex integrates spatial and non-spatial information for episodic memory."
    },
    {
      "@id": "ns:Subiculum",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Subiculum",
      "rdfs:comment": "Subiculum receives CA1 output and projects to entorhinal cortex, retrosplenial cortex, and subcortical structures. It contains place cells and boundary cells. Subiculum may compare hippocampal output with cortical input to detect mismatches. It serves as a major output hub distributing processed hippocampal information to widespread brain regions for memory consolidation and spatial navigation."
    },
    {
      "@id": "ns:DentateGyrus",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Dentate Gyrus",
      "rdfs:comment": "Dentate gyrus receives entorhinal input and projects to CA3 via mossy fibers implementing pattern separation. Its granule cells fire sparsely due to strong inhibition. Adult neurogenesis in dentate gyrus may support pattern separation and memory for temporal context. Dentate gyrus orthogonalizes similar inputs reducing interference in CA3 memory storage."
    },
    {
      "@id": "ns:CA3Region",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "CA3 Region",
      "rdfs:comment": "CA3 is an autoassociative network with extensive recurrent collaterals enabling rapid one-shot learning of episodic memories and pattern completion. It receives sparse input from dentate gyrus and dense input from entorhinal cortex. CA3 generates sharp wave ripples during rest that replay experiences for consolidation. It may implement sequence learning and planning through asymmetric associations."
    },
    {
      "@id": "ns:CA1Region",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "CA1 Region",
      "rdfs:comment": "CA1 receives input from CA3 Schaffer collaterals and direct entorhinal input via temporoammonic pathway. It may detect mismatches between predicted and actual inputs signaling novelty. CA1 place cells have sharper place fields than CA3. CA1 is critical for consolidating hippocampal memories to neocortex and may implement sequence detection and prediction."
    },
    {
      "@id": "ns:Presubiculum",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Presubiculum",
      "rdfs:comment": "Presubiculum contains head direction cells firing when the animal faces specific directions independent of location. Head direction signals are maintained by a continuous attractor network integrating angular velocity signals from vestibular system. Presubiculum provides directional information to grid cells and hippocampal place cells and contributes to path integration and spatial navigation."
    },
    {
      "@id": "ns:RetrosplenialCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Retrosplenial Cortex",
      "rdfs:comment": "Retrosplenial cortex connects hippocampus with anterior thalamus and posterior cortical areas. It contains head direction cells and neurons encoding spatial view. Retrosplenial cortex translates between egocentric and allocentric reference frames and is critical for navigation and spatial memory. It may associate visual scenes with spatial locations and support spatial updating during movement."
    },
    {
      "@id": "ns:PerirhinalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Perirhinal Cortex",
      "rdfs:comment": "Perirhinal cortex receives inferior temporal cortex input and projects to entorhinal cortex and hippocampus. It is crucial for object recognition memory and represents object familiarity. Perirhinal cortex may implement familiarity-based recognition through stimulus-specific adaptation or plasticity. It also contributes to semantic memory and resolves feature ambiguity in perception."
    },
    {
      "@id": "ns:ParahippocampalCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:Hippocampus"
      ],
      "rdfs:label": "Parahippocampal Cortex",
      "rdfs:comment": "Parahippocampal cortex processes spatial and contextual information including scenes and layouts. It contains neurons representing spatial boundaries and contexts. Parahippocampal place area responds preferentially to scenes and spatial layouts. The region supports context memory, scene recognition, and provides contextual input to hippocampus for episodic memory."
    },
    {
      "@id": "ns:CableEquation",
      "@type": [
        "owl:NamedIndividual",
        "ns:CableTheory"
      ],
      "rdfs:label": "Cable Equation",
      "rdfs:comment": "The cable equation describes voltage as a function of time and space along neuronal cables including dendrites and axons. It is derived from conservation of charge and Ohm's law. Solutions reveal characteristic length and time constants determining signal attenuation and filtering properties. The cable equation is fundamental for understanding dendritic integration and forms the basis of compartmental modeling."
    },
    {
      "@id": "ns:NernstEquation",
      "@type": [
        "owl:NamedIndividual",
        "ns:MembranePotential"
      ],
      "rdfs:label": "Nernst Equation",
      "rdfs:comment": "The Nernst equation calculates the equilibrium potential for an ion based on its concentration gradient across the membrane. It predicts reversal potentials where net ion flow is zero. For example, potassium equilibrium is typically -90mV while sodium equilibrium is +60mV. The Nernst equation relates thermodynamics to electrical potentials and is fundamental for understanding resting potential and driving forces."
    },
    {
      "@id": "ns:GoldmanEquation",
      "@type": [
        "owl:NamedIndividual",
        "ns:MembranePotential"
      ],
      "rdfs:label": "Goldman-Hodgkin-Katz Equation",
      "rdfs:comment": "The Goldman-Hodgkin-Katz equation predicts membrane potential from concentrations and permeabilities of multiple ion species. It extends the Nernst equation to multiple ions assuming constant field. The GHK equation shows how membrane potential depends on relative permeabilities - at rest mainly potassium, during action potentials transiently sodium. It accurately predicts resting potential and current-voltage relationships."
    },
    {
      "@id": "ns:SpaceClamp",
      "@type": [
        "owl:NamedIndividual",
        "ns:CompartmentalModel"
      ],
      "rdfs:label": "Space Clamp",
      "rdfs:comment": "Space clamp maintains uniform voltage across a cell or region using multiple electrodes or in isolated membrane patches. This allows measurement of ionic currents without contamination from spatial voltage gradients. Space clamp is essential for characterizing voltage-gated channel properties and deriving conductance-based model parameters. Hodgkin and Huxley used space clamp in squid axon."
    },
    {
      "@id": "ns:VoltageClamp",
      "@type": [
        "owl:NamedIndividual",
        "ns:CompartmentalModel"
      ],
      "rdfs:label": "Voltage Clamp",
      "rdfs:comment": "Voltage clamp holds membrane potential constant while measuring current required. This isolates ionic currents from capacitive currents and enables characterization of voltage-gated conductances. Voltage clamp with pharmacological blockers isolates individual channel types. It revealed voltage and time dependence of sodium and potassium conductances underlying action potentials and is fundamental for biophysical characterization."
    },
    {
      "@id": "ns:CurrentClamp",
      "@type": [
        "owl:NamedIndividual",
        "ns:CompartmentalModel"
      ],
      "rdfs:label": "Current Clamp",
      "rdfs:comment": "Current clamp injects specified current while recording membrane potential. This mimics natural conditions where neurons receive synaptic currents. Current clamp characterizes input-output relationships, firing patterns, and integration properties. It reveals phenomena like spike-frequency adaptation, resonance, and rebound firing. Current clamp combined with dynamic clamp enables insertion of virtual conductances."
    },
    {
      "@id": "ns:DynamicClamp",
      "@type": [
        "owl:NamedIndividual",
        "ns:CompartmentalModel"
      ],
      "rdfs:label": "Dynamic Clamp",
      "rdfs:comment": "Dynamic clamp adds virtual conductances or synaptic inputs computed in real time from recorded membrane potential. This enables testing effects of specific channels, synaptic inputs, or network connections. Dynamic clamp has revealed roles of specific conductances in firing patterns, created artificial electrical synapses, and tested network models. It bridges computational and experimental neuroscience."
    },
    {
      "@id": "ns:PatchClamp",
      "@type": [
        "owl:NamedIndividual",
        "ns:CompartmentalModel"
      ],
      "rdfs:label": "Patch Clamp",
      "rdfs:comment": "Patch clamp records currents through ion channels using a glass pipette sealed to a membrane patch. Configurations include cell-attached, inside-out, outside-out, and whole-cell. Patch clamp enabled recording single channel currents revealing stochastic gating and unitary conductances. Whole-cell patch clamp is the standard method for intracellular recording from small neurons. It revolutionized ion channel biophysics."
    },
    {
      "@id": "ns:SharpenedTuning",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReceptiveField"
      ],
      "rdfs:label": "Sharpened Tuning",
      "rdfs:comment": "Sharpened tuning refers to enhanced selectivity of neurons through cortical processing beyond what is inherited from feedforward inputs. Mechanisms include lateral inhibition, recurrent excitation among similarly tuned neurons, and divisive normalization. Sharpened tuning increases discriminability and efficiency of neural codes. It emerges through cortical circuitry and can be modulated by attention and learning."
    },
    {
      "@id": "ns:CenterSurroundReceptiveField",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReceptiveField"
      ],
      "rdfs:label": "Center-Surround Receptive Field",
      "rdfs:comment": "Center-surround receptive fields have antagonistic center and surround regions common in retina, LGN, and early cortex. They enhance contrast and edges through lateral inhibition. ON-center cells are excited by light in center and inhibited by surround illumination; OFF-center show opposite. Center-surround organization implements spatial filtering and edge enhancement."
    },
    {
      "@id": "ns:SimpleCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Simple Cell",
      "rdfs:comment": "Simple cells in V1 have orientation-selective elongated receptive fields with distinct ON and OFF subregions. They respond to oriented edges and gratings at specific positions. Simple cell receptive fields are well fit by Gabor functions. They may arise from aligned LGN inputs and serve as linear filters extracting oriented features. Simple cells feed into complex cells."
    },
    {
      "@id": "ns:ComplexCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Complex Cell",
      "rdfs:comment": "Complex cells in V1 are orientation-selective like simple cells but respond throughout their receptive fields without distinct ON/OFF subregions. They show phase invariance, responding to oriented edges regardless of exact position. Complex cells may arise from pooling simple cell outputs or from cortical mechanisms like recurrent inhibition. They provide more invariant orientation representations."
    },
    {
      "@id": "ns:EndStoppedCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "End-Stopped Cell",
      "rdfs:comment": "End-stopped cells (hypercomplex cells) respond to edges or bars of limited length with inhibition from beyond optimal length. They are sensitive to corners, curves, and line endings. End-stopping arises from additional antagonistic regions flanking classical receptive fields. These cells may contribute to contour completion, texture segmentation, and representing shape complexity."
    },
    {
      "@id": "ns:DirectionSelectiveCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Direction-Selective Cell",
      "rdfs:comment": "Direction-selective cells respond more strongly to motion in a preferred direction than the opposite null direction. They are common in cortical area MT and also found in V1. Direction selectivity arises from spatiotemporal filtering combining delayed inputs from different locations. Models include Reichardt detectors, delayed excitation, or direction-selective inhibition. These cells process visual motion."
    },
    {
      "@id": "ns:BinocularCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Binocular Cell",
      "rdfs:comment": "Binocular cells receive input from both eyes with receptive fields at corresponding retinal positions. Disparity-selective cells are tuned to specific binocular disparities enabling stereoscopic depth perception. Binocular cells emerge through experience-dependent matching of inputs from the two eyes during development. Ocular dominance reflects relative input strength from each eye."
    },
    {
      "@id": "ns:FaceSelectiveCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:InferiorTemporalCortex"
      ],
      "rdfs:label": "Face-Selective Cell",
      "rdfs:comment": "Face-selective cells in inferior temporal cortex respond strongly to faces compared to other objects. They show invariance to position, size, and partially to viewpoint. Populations encode face identity through distributed representations. Face cells are concentrated in face patches identified by fMRI. They may reflect experience-dependent learning of important object category with expertise."
    },
    {
      "@id": "ns:BodySelectiveCell",
      "@type": [
        "owl:NamedIndividual",
        "ns:InferiorTemporalCortex"
      ],
      "rdfs:label": "Body-Selective Cell",
      "rdfs:comment": "Body-selective cells respond preferentially to bodies and body parts compared to other objects or faces. They are found in lateral inferior temporal cortex including extrastriate body area. Body-selective cells show some invariance to viewpoint and configuration. They may support action perception, social cognition, and body representation in mirror neuron systems."
    },
    {
      "@id": "ns:MirrorNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Mirror Neuron",
      "rdfs:comment": "Mirror neurons fire both when performing an action and when observing others perform the same action. Discovered in ventral premotor cortex of monkeys, they match observed and executed actions. Mirror neurons may support action understanding, imitation learning, and theory of mind. Their role in humans and autism is debated. They demonstrate sensorimotor integration."
    },
    {
      "@id": "ns:CanonicalNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Canonical Neuron",
      "rdfs:comment": "Canonical neurons in premotor cortex respond both to object observation and to grasping actions appropriate for that object. They match object affordances to motor programs. Canonical neurons may enable direct visual-motor transformation and support action selection based on object properties. They demonstrate how visual and motor representations interact for affordance-based action."
    },
    {
      "@id": "ns:CorollaryDischarge",
      "@type": [
        "owl:NamedIndividual",
        "ns:ForwardModel"
      ],
      "rdfs:label": "Corollary Discharge",
      "rdfs:comment": "Corollary discharge is a copy of motor command sent to sensory areas to predict sensory consequences of self-generated movements. It enables distinction between self-generated and external sensory events. Corollary discharge underlies visual stability across saccades, cancellation of reafference during movement, and predictive remapping of receptive fields. It is generated by forward models."
    },
    {
      "@id": "ns:EfferenceCopy",
      "@type": [
        "owl:NamedIndividual",
        "ns:ForwardModel"
      ],
      "rdfs:label": "Efference Copy",
      "rdfs:comment": "Efference copy is synonymous with corollary discharge - a copy of motor command used to predict sensory consequences. The term emphasizes the motor output (efference) being copied. Efference copy enables sensory prediction, motor control without delays, and distinguishing self from external causation. It is fundamental for coordinated movement and body ownership."
    },
    {
      "@id": "ns:StateEstimation",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "State Estimation",
      "rdfs:comment": "State estimation combines noisy sensory measurements with predictions from forward models to estimate current body and world states. Optimal state estimation given uncertainty is implemented by Kalman filtering in linear systems. The brain performs analogous estimation combining visual, proprioceptive, and predicted state information. State estimation enables accurate reaching despite sensory delays and noise."
    },
    {
      "@id": "ns:OptimalCueCombination",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Optimal Cue Combination",
      "rdfs:comment": "Optimal cue combination weights multiple sensory cues according to their reliabilities to minimize estimation variance. More reliable cues receive higher weights matching maximum likelihood estimation. Humans combine visual and haptic size information, visual and vestibular heading, and audio-visual location optimally. This demonstrates Bayesian inference in multisensory integration and provides evidence for probabilistic neural representations."
    },
    {
      "@id": "ns:DriftDiffusionModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:DecisionMaking"
      ],
      "rdfs:label": "Drift-Diffusion Model",
      "rdfs:comment": "The drift-diffusion model describes decision making as noisy accumulation of evidence to a threshold. Drift rate reflects evidence strength, threshold determines speed-accuracy tradeoff, and noise represents trial-to-trial variability. The model accounts for choice accuracy, reaction time distributions, and speed-accuracy tradeoffs. Neural correlates include ramping activity in parietal cortex and superior colliculus."
    },
    {
      "@id": "ns:RaceModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:DecisionMaking"
      ],
      "rdfs:label": "Race Model",
      "rdfs:comment": "Race models describe decision making as independent accumulators for each choice racing to threshold. The first accumulator to reach threshold determines the choice. Race models differ from drift-diffusion by lacking inhibition between accumulators. They can account for many behavioral phenomena but predict different neural dynamics and network implementations than competing accumulator models with mutual inhibition."
    },
    {
      "@id": "ns:AttractorModel",
      "@type": [
        "owl:NamedIndividual",
        "ns:DecisionMaking"
      ],
      "rdfs:label": "Attractor Model of Decision Making",
      "rdfs:comment": "Attractor models implement decision making through competing populations with mutual inhibition forming discrete attractors for each choice. Noise and input drive transitions between undecided state and decision attractors. Attractor models predict bistability, hysteresis, and confidence-related phenomena. They provide mechanistic neural implementation of decision processes and are supported by recordings from decision-related cortical areas."
    },
    {
      "@id": "ns:UrgencySignal",
      "@type": [
        "owl:NamedIndividual",
        "ns:DecisionMaking"
      ],
      "rdfs:label": "Urgency Signal",
      "rdfs:comment": "Urgency signals increase over time lowering decision thresholds to ensure timely decisions. They implement time pressure and prevent decisions from taking arbitrarily long. Urgency signals may be implemented by increasing gain or lowering threshold over time. They explain behavior in time-limited tasks and changes in speed-accuracy tradeoffs within trials. Neural correlates may include ramping baseline activity."
    },
    {
      "@id": "ns:ConfidenceEncoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:DecisionMaking"
      ],
      "rdfs:label": "Confidence Encoding",
      "rdfs:comment": "Confidence in decisions can be encoded in neural activity related to evidence strength, balance of evidence, or post-decision dynamics. Confidence guides metacognitive judgments and bet-sizing. Neural correlates include activity in prefrontal cortex, parietal cortex, and ventral striatum. Confidence may be computed from the same evidence used for decisions or from post-decision monitoring."
    },
    {
      "@id": "ns:QLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Q-Learning",
      "rdfs:comment": "Q-learning is a model-free reinforcement learning algorithm that learns state-action values (Q-values) representing expected cumulative reward. It uses temporal difference errors to update Q-values without requiring a model of environment dynamics. Q-learning can learn optimal policies through exploration. Variants include SARSA and double Q-learning. The algorithm relates to striatal learning and dopamine function."
    },
    {
      "@id": "ns:ActorCritic",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Actor-Critic",
      "rdfs:comment": "Actor-critic methods separate policy (actor) and value function (critic) learning. The critic evaluates actions using TD errors, which the actor uses to update the policy. This separation may map to basal ganglia architecture with striatum as critic and premotor areas as actor. Actor-critic enables continuous actions and policy gradient methods. It bridges value-based and policy-based reinforcement learning."
    },
    {
      "@id": "ns:ModelBasedRL",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Model-Based Reinforcement Learning",
      "rdfs:comment": "Model-based reinforcement learning learns a model of environment dynamics and uses it for planning and prediction. It enables faster learning from less experience, credit assignment, and goal-directed behavior. Model-based RL involves prefrontal cortex and hippocampus. It competes and cooperates with model-free habitual systems. Humans and animals use both model-based and model-free learning."
    },
    {
      "@id": "ns:HabitualLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Habitual Learning",
      "rdfs:comment": "Habitual learning creates stimulus-response associations through repetition that become insensitive to outcome value. Habits are fast, efficient, and automatic but inflexible. They are mediated by dorsolateral striatum and reflect model-free reinforcement learning. Habits compete with goal-directed control involving dorsomedial striatum and prefrontal cortex. Transition from goal-directed to habitual control occurs with overtraining."
    },
    {
      "@id": "ns:ExplorationExploitation",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Exploration-Exploitation",
      "rdfs:comment": "The exploration-exploitation tradeoff balances trying new actions to gather information (exploration) versus choosing known rewarding actions (exploitation). Strategies include epsilon-greedy, softmax, and upper confidence bounds. Humans and animals explore more when uncertainty is high or stakes are low. Exploration may be implemented through noradrenergic modulation, random noise, or directed uncertainty-seeking."
    },
    {
      "@id": "ns:RewardPredictionError",
      "@type": [
        "owl:NamedIndividual",
        "ns:RewardPrediction"
      ],
      "rdfs:label": "Reward Prediction Error",
      "rdfs:comment": "Reward prediction error is the difference between received and predicted reward driving learning in temporal difference algorithms. Dopamine neurons signal reward prediction errors - increases for unexpected rewards, no response for predicted rewards, and decreases for omitted expected rewards. RPEs drive updating of value predictions and action selection. This provides a biological implementation of temporal difference learning."
    },
    {
      "@id": "ns:ValueFunction",
      "@type": [
        "owl:NamedIndividual",
        "ns:RewardPrediction"
      ],
      "rdfs:label": "Value Function",
      "rdfs:comment": "Value functions predict cumulative future reward from states (state values) or state-action pairs (Q-values). They guide action selection toward high-value states and actions. Value functions are learned through temporal difference methods or computed through planning with models. Neural correlates include orbitofrontal cortex, ventromedial prefrontal cortex, and ventral striatum."
    },
    {
      "@id": "ns:PolicyGradient",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Policy Gradient",
      "rdfs:comment": "Policy gradient methods directly optimize action selection policies by following gradients of expected reward. They can handle continuous actions and stochastic policies. Policy gradients use reward outcomes to adjust action probabilities - increasing probability of rewarded actions. The REINFORCE algorithm is a classic policy gradient method. These methods may relate to motor learning in cerebellum and motor cortex."
    },
    {
      "@id": "ns:ProbabilisticPopulationCode",
      "@type": [
        "owl:NamedIndividual",
        "ns:PopulationCoding"
      ],
      "rdfs:label": "Probabilistic Population Code",
      "rdfs:comment": "Probabilistic population codes represent probability distributions over stimulus variables through neural population activity. They encode both estimate and uncertainty. Different coding schemes include linear probabilistic codes and distributional codes. Population activity can be decoded to extract means, variances, and full distributions. This framework unifies population coding with Bayesian inference."
    },
    {
      "@id": "ns:MaximumLikelihood",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Maximum Likelihood",
      "rdfs:comment": "Maximum likelihood estimation finds parameter values that maximize the probability of observed data. In neural decoding, it finds the stimulus most likely to have generated observed neural responses. ML estimation is optimal when priors are flat. Neurons with bell-shaped tuning curves naturally implement ML through population vector decoding. ML provides benchmark for evaluating neural coding efficiency."
    },
    {
      "@id": "ns:BayesianDecoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Bayesian Decoding",
      "rdfs:comment": "Bayesian decoding combines likelihood of neural responses given stimuli with prior probabilities to infer posterior probability distributions over stimuli. It is optimal under appropriate assumptions and accounts for uncertainty. Bayesian decoders outperform maximum likelihood when stimuli are non-uniform. Evidence suggests the brain uses prior information in perception and decision making consistent with Bayesian decoding."
    },
    {
      "@id": "ns:PredictiveCoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Predictive Coding",
      "rdfs:comment": "Predictive coding proposes that the brain predicts sensory inputs and only processes prediction errors. Top-down predictions are compared to bottom-up inputs, and mismatches propagate as error signals. This implements hierarchical Bayesian inference efficiently. Predictive coding may explain repetition suppression, mismatch responses, and attention effects. It provides a framework unifying perception, learning, and action."
    },
    {
      "@id": "ns:FreeEnergy",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Free Energy Principle",
      "rdfs:comment": "The free energy principle proposes that the brain minimizes a quantity (variational free energy) upper-bounding surprise about sensory inputs. This is equivalent to maximizing evidence for an internal model. Minimizing free energy through perception (updating beliefs) and action (sampling expected inputs) implements Bayesian inference and explains homeostasis, allostasis, and adaptive behavior."
    },
    {
      "@id": "ns:ActiveInference",
      "@type": [
        "owl:NamedIndividual",
        "ns:BayesianInference"
      ],
      "rdfs:label": "Active Inference",
      "rdfs:comment": "Active inference extends free energy minimization to action selection. Instead of optimizing expected reward, agents select actions that minimize expected free energy, seeking information and familiar states. This unifies perception and action under a single imperative. Active inference provides a framework for understanding exploration, curiosity, and goal-directed behavior as consequences of minimizing uncertainty."
    },
    {
      "@id": "ns:FisherInformation",
      "@type": [
        "owl:NamedIndividual",
        "ns:InformationTheory"
      ],
      "rdfs:label": "Fisher Information",
      "rdfs:comment": "Fisher information quantifies how much information neural responses carry about small changes in stimulus parameters. It bounds discrimination performance through Cram\u00e9r-Rao inequality. Fisher information is maximized by neurons with steep tuning curve slopes at stimulus value. It provides measures of coding precision and efficiency. Population Fisher information sums contributions from neurons."
    },
    {
      "@id": "ns:NeuralDecoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralCode"
      ],
      "rdfs:label": "Neural Decoding",
      "rdfs:comment": "Neural decoding extracts information about stimuli or intentions from neural activity. Decoding methods include population vectors, maximum likelihood, Bayesian inference, and machine learning classifiers. Decoding performance indicates information content of neural representations. Successful decoding enables brain-computer interfaces. Comparing decoding approaches tests theories about how the brain reads out neural codes."
    },
    {
      "@id": "ns:SparseCoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralCode"
      ],
      "rdfs:label": "Sparse Coding",
      "rdfs:comment": "Sparse coding represents stimuli using few active neurons from a larger population. Sparse codes are energy-efficient, reduce interference, and increase storage capacity. They emerge from learning algorithms that maximize sparseness or minimize description length. V1 simple cell receptive fields resemble independent components of natural images learned through sparse coding. Sparse representations are found throughout cortex."
    },
    {
      "@id": "ns:EfficientCoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralCode"
      ],
      "rdfs:label": "Efficient Coding",
      "rdfs:comment": "Efficient coding hypothesizes that neural systems optimize information transmission given constraints like energy, noise, and limited dynamic range. Predictions include whitening of natural stimulus statistics, adaptation to stimulus statistics, and decorrelation. Efficient coding explains center-surround receptive fields, contrast adaptation, and properties of sensory systems. It provides a normative framework for understanding neural representations."
    },
    {
      "@id": "ns:Decorrelation",
      "@type": [
        "owl:NamedIndividual",
        "ns:NeuralCode"
      ],
      "rdfs:label": "Decorrelation",
      "rdfs:comment": "Decorrelation removes redundancy in neural representations by making responses statistically independent. Decorrelation increases coding efficiency and channel capacity. Mechanisms include center-surround antagonism, lateral inhibition, and whitening. Retinal and LGN processing decorrelates natural images. Independent component analysis learns decorrelated representations matching V1 simple cells. Decorrelation is a key principle of efficient coding."
    },
    {
      "@id": "ns:Normalization",
      "@type": [
        "owl:NamedIndividual",
        "ns:GainControl"
      ],
      "rdfs:label": "Divisive Normalization",
      "rdfs:comment": "Divisive normalization divides neural responses by a measure of population activity implementing gain control. It accounts for contrast normalization, surround suppression, attention effects, and multisensory integration. Normalization maintains responses within dynamic range and implements efficient coding. It is a canonical cortical computation implemented across sensory modalities and brain regions. Normalization may arise from inhibitory circuits or synaptic depression."
    },
    {
      "@id": "ns:ContrastGainControl",
      "@type": [
        "owl:NamedIndividual",
        "ns:GainControl"
      ],
      "rdfs:label": "Contrast Gain Control",
      "rdfs:comment": "Contrast gain control adjusts neural sensitivity to match stimulus contrast range through adaptation and normalization. High contrast reduces gain keeping responses within dynamic range. This enables encoding contrast changes over a wide range. Mechanisms include synaptic depression, network interactions, and intrinsic adaptation. Contrast gain control is ubiquitous in sensory systems implementing efficient coding."
    },
    {
      "@id": "ns:AttentionalGain",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualAttention"
      ],
      "rdfs:label": "Attentional Gain",
      "rdfs:comment": "Attention increases response gain of neurons representing attended stimuli - multiplicative enhancement of stimulus-evoked responses. Gain changes are observed in visual cortex, parietal cortex, and higher areas. Attentional gain enhances weak stimuli more than strong ones in some studies. Mechanisms may involve modulation of effective input strength or normalization parameters. Gain modulation implements signal enhancement."
    },
    {
      "@id": "ns:SpatialAttention",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualAttention"
      ],
      "rdfs:label": "Spatial Attention",
      "rdfs:comment": "Spatial attention enhances processing at attended locations through top-down signals from frontal and parietal cortex to sensory cortex. It improves detection, discrimination, and speeds responses at attended locations. Spatial attention shifts the attentional spotlight and can be covert (without eye movements). Priority maps in parietal cortex and FEF represent attended locations. Spatial attention may implement winner-take-all competition."
    },
    {
      "@id": "ns:FeatureAttention",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualAttention"
      ],
      "rdfs:label": "Feature-Based Attention",
      "rdfs:comment": "Feature-based attention enhances processing of attended features (color, orientation, motion) throughout the visual field, not just at attended locations. It modulates neurons tuned to attended features even when attention is directed elsewhere spatially. Feature attention enables selection of objects sharing features and enhances feature discrimination. It may involve feature-specific feedback from higher areas to sensory cortex."
    },
    {
      "@id": "ns:ChangeBlindness",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualAttention"
      ],
      "rdfs:label": "Change Blindness",
      "rdfs:comment": "Change blindness is failure to detect large changes in scenes when changes occur during disruptions like eye movements or blinks. It demonstrates limitations of visual memory and attention - only attended objects are represented in detail. Change blindness shows that subjective visual experience of rich detail is an illusion. It has implications for understanding consciousness, memory, and attentional selection."
    },
    {
      "@id": "ns:Neuromodulation",
      "@type": "owl:Class",
      "rdfs:label": "Neuromodulation",
      "rdfs:comment": "Neuromodulation refers to the alteration of neuronal and network properties by neuromodulators like dopamine, serotonin, acetylcholine, and neuropeptides. Neuromodulators act over longer timescales than fast neurotransmitters and affect excitability, plasticity, and gain. Neuromodulation enables behavioral state control, attention, arousal, and motivation."
    },
    {
      "@id": "ns:Neurogenesis",
      "@type": "owl:Class",
      "rdfs:label": "Neurogenesis",
      "rdfs:comment": "Neurogenesis is the generation of new neurons continuing into adulthood in specific brain regions including hippocampal dentate gyrus and olfactory bulb. Adult neurogenesis is regulated by experience, stress, and learning. New neurons may support pattern separation, temporal encoding, and adaptation to new environments. Neurogenesis declines with age."
    },
    {
      "@id": "ns:Neuroplasticity",
      "@type": "owl:Class",
      "rdfs:label": "Neuroplasticity",
      "rdfs:comment": "Neuroplasticity encompasses all activity-dependent changes in neural structure and function including synaptic plasticity, structural plasticity, homeostatic plasticity, and metaplasticity. Plasticity enables learning, memory, development, and recovery from injury. It operates across timescales from milliseconds to years and spatial scales from syn apses to whole brain networks."
    },
    {
      "@id": "ns:StructuralPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Structural Plasticity",
      "rdfs:comment": "Structural plasticity involves physical changes in neural connections including growth and retraction of dendritic spines, axonal sprouting, and formation of new synapses. It occurs during development, learning, and recovery from injury. Structural plasticity can stabilize functional changes and enable large-scale circuit reorganization. Imaging reveals spine dynamics related to learning.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuroplasticity"
      }
    },
    {
      "@id": "ns:HomeostaticPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Homeostatic Plasticity",
      "rdfs:comment": "Homeostatic plasticity maintains neural activity and network stability despite perturbations through compensatory changes in excitability or synaptic strengths. Mechanisms include synaptic scaling adjusting all synapses on a neuron and intrinsic plasticity modifying ion channel expression. Homeostatic plasticity prevents runaway excitation and maintains information processing capacity during learning.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuroplasticity"
      }
    },
    {
      "@id": "ns:Metaplasticity",
      "@type": "owl:Class",
      "rdfs:label": "Metaplasticity",
      "rdfs:comment": "Metaplasticity is plasticity of plasticity - activity-dependent changes in the ability to induce subsequent plasticity. Prior activity can shift thresholds for LTP and LTD through mechanisms like NMDA receptor phosphorylation. Metaplasticity implements sliding modification thresholds preventing saturation and enabling continued learning. It may underlie priming effects and savings in motor learning.",
      "rdfs:subClassOf": {
        "@id": "ns:Neuroplasticity"
      }
    },
    {
      "@id": "ns:CriticalPeriod",
      "@type": "owl:Class",
      "rdfs:comment": "Critical periods are developmental windows of heightened plasticity when experience has lasting effects on circuit development. Visual cortex ocular dominance plasticity has a well-studied critical period. Critical periods are regulated by maturation of inhibition, extracellular matrix, and molecular brakes on plasticity. Understanding critical periods has implications for amblyopia treatment and recovery from injury.",
      "rdfs:label": "Critical Period"
    },
    {
      "@id": "ns:SynapticScaling",
      "@type": "owl:Class",
      "rdfs:label": "Synaptic Scaling",
      "rdfs:comment": "Synaptic scaling is a form of homeostatic plasticity that multiplicatively adjusts all synaptic weights on a neuron to maintain firing rate setpoints. It occurs over hours to days in response to chronic changes in activity. Synaptic scaling preserves relative synaptic weights while shifting overall gain. Mechanisms involve changes in AMPA receptor expression regulated by calcium and activity sensors.",
      "rdfs:subClassOf": {
        "@id": "ns:HomeostaticPlasticity"
      }
    },
    {
      "@id": "ns:IntrinsicPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Intrinsic Plasticity",
      "rdfs:comment": "Intrinsic plasticity modifies neuronal excitability through changes in ion channel expression and properties. It adjusts input-output gain, threshold, and firing patterns. Intrinsic plasticity can complement synaptic plasticity, implement homeostasis, or enable context-dependent modulation. Activity-dependent changes in sodium, potassium, and HCN channels alter excitability across timescales from minutes to days.",
      "rdfs:subClassOf": {
        "@id": "ns:HomeostaticPlasticity"
      }
    },
    {
      "@id": "ns:ShortTermPlasticity",
      "@type": "owl:Class",
      "rdfs:label": "Short-Term Plasticity",
      "rdfs:comment": "Short-term plasticity includes facilitation and depression occurring on timescales of milliseconds to seconds. Facilitation increases release probability with repeated activation through residual calcium. Depression depletes readily releasable vesicles. Short-term plasticity acts as a high-pass or low-pass filter shaping temporal dynamics. It enables adaptation, gain control, and temporal filtering of synaptic transmission.",
      "rdfs:subClassOf": {
        "@id": "ns:SynapticPlasticity"
      }
    },
    {
      "@id": "ns:PairedPulseFacilitation",
      "@type": "owl:Class",
      "rdfs:label": "Paired-Pulse Facilitation",
      "rdfs:comment": "Paired-pulse facilitation is enhanced response to the second of two closely spaced stimuli due to residual presynaptic calcium increasing release probability. PPF magnitude decreases with increasing interstimulus interval reflecting calcium decay. PPF is used to probe presynaptic release probability and calcium dynamics. Synapses with low initial release probability show stronger PPF.",
      "rdfs:subClassOf": {
        "@id": "ns:ShortTermPlasticity"
      }
    },
    {
      "@id": "ns:SynapticDepression",
      "@type": "owl:Class",
      "rdfs:label": "Synaptic Depression",
      "rdfs:comment": "Synaptic depression is decreased response to repeated stimulation due to depletion of readily releasable vesicles or receptor desensitization. Depression acts as a high-pass filter emphasizing transients. It contributes to adaptation, gain control, and can enhance sensitivity to stimulus changes. Recovery from depression depends on vesicle replenishment rates typically 100ms to seconds.",
      "rdfs:subClassOf": {
        "@id": "ns:ShortTermPlasticity"
      }
    },
    {
      "@id": "ns:MetabotropicReceptor",
      "@type": "owl:Class",
      "rdfs:label": "Metabotropic Receptor",
      "rdfs:comment": "Metabotropic receptors are G-protein coupled receptors that modulate cellular processes through second messenger cascades. They mediate slow, long-lasting effects on neuronal excitability and synaptic transmission. Metabotropic glutamate receptors (mGluRs) and GABA-B receptors regulate presynaptic release and postsynaptic excitability. Metabotropic signaling enables neuromodulation and metaplasticity.",
      "rdfs:subClassOf": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:IonotrotropicReceptor",
      "@type": "owl:Class",
      "rdfs:label": "Ionotropic Receptor",
      "rdfs:comment": "Ionotropic receptors are ligand-gated ion channels that rapidly change membrane potential upon neurotransmitter binding. They mediate fast synaptic transmission on millisecond timescales. Examples include AMPA, NMDA, GABA-A, and nicotinic receptors. Ion selectivity determines whether responses are excitatory or inhibitory. Receptor kinetics shape temporal dynamics of synaptic currents.",
      "rdfs:subClassOf": {
        "@id": "ns:Receptor"
      }
    },
    {
      "@id": "ns:ComputationalNeuroscience",
      "@type": "owl:Class",
      "rdfs:label": "Computational Neuroscience",
      "rdfs:comment": "Computational neuroscience uses mathematical models, theoretical analysis, and computer simulations to understand the brain. It spans multiple levels from molecules to cognition. Approaches include biophysical models, network models, and normative theories. Computational neuroscience complements experimental neuroscience by testing hypotheses, making predictions, and revealing principles of neural computation."
    },
    {
      "@id": "ns:TheoreticalNeuroscience",
      "@type": "owl:Class",
      "rdfs:label": "Theoretical Neuroscience",
      "rdfs:comment": "Theoretical neuroscience develops mathematical frameworks and principles for understanding neural systems. It includes dynamical systems theory, information theory, statistical inference, and optimization. Theoretical approaches identify fundamental constraints, optimal strategies, and universal principles. They complement detailed models by providing conceptual understanding and testable predictions about neural function.",
      "rdfs:subClassOf": {
        "@id": "ns:ComputationalNeuroscience"
      }
    },
    {
      "@id": "ns:NeuromorphicEngineering",
      "@type": "owl:Class",
      "rdfs:label": "Neuromorphic Engineering",
      "rdfs:comment": "Neuromorphic engineering designs hardware and algorithms inspired by neural systems. Neuromorphic chips implement spiking neural networks with low power consumption using analog circuits or mixed analog-digital designs. Applications include robotics, sensory processing, and machine learning. Neuromorphic systems enable real-time processing and testing of neural network models in embodied systems.",
      "rdfs:subClassOf": {
        "@id": "ns:ComputationalNeuroscience"
      }
    },
    {
      "@id": "ns:MachineLearning",
      "@type": "owl:Class",
      "rdfs:label": "Machine Learning",
      "rdfs:comment": "Machine learning develops algorithms that learn from data to make predictions or decisions. Artificial neural networks are inspired by biological neurons though differ significantly. Deep learning with multi-layer networks achieves impressive performance on perception and cognition tasks. Comparing artificial and biological learning reveals commonalities and differences in learning algorithms, representations, and computations."
    },
    {
      "@id": "ns:DeepLearning",
      "@type": "owl:Class",
      "rdfs:label": "Deep Learning",
      "rdfs:comment": "Deep learning uses multi-layer neural networks to learn hierarchical representations. Convolutional networks process images, recurrent networks process sequences, and transformers use attention mechanisms. Deep networks trained on large datasets achieve human-level or superhuman performance on many tasks. Comparing deep networks to cortical processing reveals similarities in hierarchical feature extraction and differences in learning mechanisms.",
      "rdfs:subClassOf": {
        "@id": "ns:MachineLearning"
      }
    },
    {
      "@id": "ns:ConvolutionalNeuralNetwork",
      "@type": "owl:Class",
      "rdfs:label": "Convolutional Neural Network",
      "rdfs:comment": "Convolutional neural networks use layers of convolution and pooling operations to process images. They learn hierarchical visual features from edges to objects. CNNs achieve excellent performance on image classification and detection. Their hierarchical organization and learned filters show similarities to visual cortex though differ in connectivity patterns, learning rules, and dynamics.",
      "rdfs:subClassOf": {
        "@id": "ns:DeepLearning"
      }
    },
    {
      "@id": "ns:respondsTo",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "responds to",
      "rdfs:comment": "This property relates neurons or brain regions to the stimuli or conditions they respond to. Stimulus selectivity defines what information neurons encode. Understanding what neurons respond to across the hierarchy from simple features to complex objects reveals principles of sensory processing and representation.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:SensoryProcessing"
      }
    },
    {
      "@id": "ns:inhibits",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "inhibits",
      "rdfs:comment": "This property represents inhibitory influences between neurons or brain regions. Inhibition is essential for gain control, selectivity, oscillations, and preventing runaway excitation. Different interneuron types provide perisomatic versus dendritic inhibition implementing distinct computational functions. Inhibitory connections shape network dynamics and enable winner-take-all competition.",
      "rdfs:domain": {
        "@id": "ns:Interneuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:excites",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "excites",
      "rdfs:comment": "This property represents excitatory connections between neurons. Excitation drives spiking and spreads activity through networks. Excitatory connections are modified by learning and determine information flow. Balance of excitation and inhibition regulates network state and maintains stability while enabling rich dynamics.",
      "rdfs:domain": {
        "@id": "ns:PyramidalNeuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:connects",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "connects",
      "rdfs:comment": "This property represents anatomical and functional connections between brain regions. Connection patterns determine information routing and enable coordinated processing. Connectomics maps connectivity at multiple scales from synaptic to whole-brain. Understanding connectivity is crucial for relating structure to function.",
      "rdfs:domain": {
        "@id": "ns:Hippocampus"
      },
      "rdfs:range": {
        "@id": "ns:PrefrontalCortex"
      }
    },
    {
      "@id": "ns:modulates",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "modulates",
      "rdfs:comment": "This property represents modulatory influences that change neural processing without directly driving activity. Neuromodulators alter gain, plasticity thresholds, and network states. Modulation implements behavioral state control, attention, arousal, and enables context-dependent computation. Modulatory systems have widespread projections affecting multiple brain regions.",
      "rdfs:domain": {
        "@id": "ns:Neurotransmitter"
      },
      "rdfs:range": {
        "@id": "ns:NeuralNetwork"
      }
    },
    {
      "@id": "ns:receivesInputFrom",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "receives input from",
      "rdfs:comment": "This property represents the sources of inputs to neurons or brain regions. Input connectivity determines what information is available for processing. Different input sources provide different types of information - feedforward inputs provide sensory data while feedback inputs provide predictions and context. Understanding input organization reveals computational architecture.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:sendsOutputTo",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "sends output to",
      "rdfs:comment": "This property represents the targets of neuronal outputs. Output connectivity determines where processed information is distributed and what downstream computations it influences. Neurons can have multiple output targets enabling parallel distribution of information. Output patterns reveal functional roles and downstream consequences of neural processing.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:representsState",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "represents state",
      "rdfs:comment": "This property relates neural populations to the state variables they represent such as position, heading, value, or object identity. Understanding what states are represented and how reveals the nature of neural codes and computations. State representations can be allocentric or egocentric, and distributed across populations.",
      "rdfs:domain": {
        "@id": "ns:PlaceCell"
      },
      "rdfs:range": {
        "@id": "ns:SpatialMemory"
      }
    },
    {
      "@id": "ns:implementsAlgorithm",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "implements algorithm",
      "rdfs:comment": "This property relates neural circuits to the algorithms or computations they implement. Understanding neural algorithms bridges neuroscience and computer science. Examples include Reichardt detectors for motion, winner-take-all for competition, and temporal difference learning for prediction. Identifying algorithms reveals computational principles.",
      "rdfs:domain": {
        "@id": "ns:NeuralNetwork"
      },
      "rdfs:range": {
        "@id": "ns:ReichardtDetector"
      }
    },
    {
      "@id": "ns:supportsFunction",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "supports function",
      "rdfs:comment": "This property relates brain structures to cognitive or behavioral functions they support. Understanding structure-function relationships is central to neuroscience. Functions emerge from network interactions rather than individual regions. Lesion studies, recordings, and stimulation reveal which structures are necessary or sufficient for functions. Multiple structures often contribute to complex functions.",
      "rdfs:domain": {
        "@id": "ns:Hippocampus"
      },
      "rdfs:range": {
        "@id": "ns:EpisodicMemory"
      }
    },
    {
      "@id": "ns:gatesInformation",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "gates information",
      "rdfs:comment": "This property represents mechanisms that control information flow. Gating can be implemented by attention, inhibition, neuromodulation, or synaptic mechanisms. Thalamic reticular nucleus gates sensory information. Working memory gates determine what enters and exits working memory. Gating enables flexible routing and filtering of information.",
      "rdfs:domain": {
        "@id": "ns:Interneuron"
      },
      "rdfs:range": {
        "@id": "ns:SensoryProcessing"
      }
    },
    {
      "@id": "ns:coordinates",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "coordinates",
      "rdfs:comment": "This property represents coordination between brain regions or neural populations. Coordination can occur through oscillatory synchronization, common inputs, or synaptic connections. Coordinated activity enables information integration, feature binding, and distributed computation. Disrupted coordination may underlie neurological and psychiatric disorders.",
      "rdfs:domain": {
        "@id": "ns:Hippocampus"
      },
      "rdfs:range": {
        "@id": "ns:PrefrontalCortex"
      }
    },
    {
      "@id": "ns:competesWith",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "competes with",
      "rdfs:comment": "This property represents competitive interactions between neurons or representations. Competition through mutual inhibition implements winner-take-all dynamics for decision making, attention, and action selection. Competitive dynamics select strongest representations while suppressing alternatives. Competition can be soft (biasing) or hard (winner-take-all).",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:synchronizesWith",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "synchronizes with",
      "rdfs:comment": "This property represents synchronization between neurons or neuronal populations. Synchrony can arise from common inputs, direct connections, or weak coupling through oscillations. Synchronized firing may bind features, route information, or enhance postsynaptic impact. Excessive synchronization can be pathological as in epilepsy. Zero-lag synchrony despite conduction delays is mechanistically interesting.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:Neuron"
      }
    },
    {
      "@id": "ns:adaptsto",
      "@type": "owl:ObjectProperty",
      "rdfs:label": "adapts to",
      "rdfs:comment": "This property represents adaptation to stimulus statistics, sensory conditions, or task demands. Adaptation optimizes coding for current context, enhances sensitivity to changes, and prevents saturation. Mechanisms include synaptic depression, intrinsic currents, and gain control. Adaptation occurs across timescales from milliseconds to days and implements efficient coding.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "ns:SensoryProcessing"
      }
    },
    {
      "@id": "ns:hasConnectivity",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has connectivity",
      "rdfs:comment": "This property quantifies connectivity strength or probability between neurons or regions. Connection probabilities vary from sparse (<10%) to dense depending on cell types and regions. Connectivity patterns determine network dynamics and computational properties. Measuring connectivity requires anatomical tracing, electron microscopy, or functional inference.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasConductance",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has conductance",
      "rdfs:comment": "This property specifies ionic conductances in nanosiemens or millisiemens determining current flow. Conductances depend on channel open probability, single channel conductance, and channel number. Maximal conductances are key parameters in conductance-based models. Different neurons have characteristic conductance densities determining their firing properties.",
      "rdfs:domain": {
        "@id": "ns:IonChannel"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasReverberation",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has reverberation",
      "rdfs:comment": "This property represents the time constant of reverberating activity in recurrent networks. Reverb eration enables short-term memory through sustained activity after stimulus offset. Time constants range from hundreds of milliseconds in working memory to seconds for decision-related activity. Reverberation stability depends on balance of excitation and inhibition.",
      "rdfs:domain": {
        "@id": "ns:RecurrentNetwork"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasSelectivity",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has selectivity",
      "rdfs:comment": "This property quantifies neuronal selectivity for stimulus features measured as discrimination index, sparseness, or tuning width. Selective neurons respond to narrow stimulus ranges while broadly tuned neurons respond to many stimuli. Selectivity affects coding efficiency and capacity. Sparse codes have high selectivity while dense codes are more distributed.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasVariability",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has variability",
      "rdfs:comment": "This property quantifies trial-to-trial variability in neural responses measured by Fano factor, coefficient of variation, or correlation. High variability limits coding precision. Variability sources include channel noise, synaptic noise, and network fluctuations. Shared variability between neurons reflects common inputs and network state. Some variability is behaviorally relevant encoding uncertainty.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasRefractory",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has refractory period",
      "rdfs:comment": "This property specifies the refractory period in milliseconds following action potentials during which neurons cannot fire again. Absolute refractory period reflects sodium channel inactivation (1-2ms) while relative refractory period reflects potassium currents and afterhyperpolarization. Refractory periods limit maximum firing rates and affect temporal coding precision.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasSpontaneousRate",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has spontaneous rate",
      "rdfs:comment": "This property specifies spontaneous firing rate in absence of explicit stimulation. Spontaneous rates range from zero in silent neurons to tens of Hz in tonically active neurons. Spontaneous activity enables rapid responses, represents baseline or prior probabilities, and maintains network in sensitive operating regime. Spontaneous rate depends on intrinsic properties and synaptic input.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasResponse",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has response magnitude",
      "rdfs:comment": "This property quantifies response magnitude to stimuli in spikes/second or other units. Response magnitudes determine signal strength and discriminability. Responses are modulated by attention, adaptation, and behavioral context. Dynamic range is the range of responses from baseline to maximum. Responses are constrained by saturation at high firing rates.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasCorrelation",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has correlation",
      "rdfs:comment": "This property quantifies correlations between neurons ranging from -1 to 1. Positive correlations reflect common inputs, reciprocal connections, or shared network states. Correlations limit information capacity of populations. Attention and learning can decorrelate responses. Understanding correlation structure is crucial for decoding population codes.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasLifetime",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has sparseness",
      "rdfs:comment": "This property quantifies population sparseness - the fraction of neurons active for a given stimulus. Sparse codes (1-5% active) have advantages for storage capacity, energy efficiency, and interference reduction. Dense codes (50%+ active) are more robust to noise. Sparseness depends on inhibition strength, threshold, and coding strategy. Measured as lifetime or population sparseness.",
      "rdfs:domain": {
        "@id": "ns:NeuralNetwork"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasTuningWidth",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has tuning width",
      "rdfs:comment": "This property specifies tuning curve width for feature-selective neurons. Narrow tuning (small width) indicates high selectivity while broad tuning indicates generalization. Tuning width affects coding efficiency - narrow tuning increases discrimination but reduces coverage. Measured as full-width at half-maximum or standard deviation of Gaussian fits to tuning curves.",
      "rdfs:domain": {
        "@id": "ns:Neuron"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasRiseTime",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has rise time",
      "rdfs:comment": "This property specifies rise time of synaptic currents or potentials in milliseconds. AMPA receptors have fast rise times (<1ms) while NMDA receptors are slower (5-10ms). Rise time affects temporal precision and integration windows. Fast rise times enable precise coincidence detection while slow rise times allow summation of inputs across time.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasDecayTime",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has decay time",
      "rdfs:comment": "This property specifies decay time constant of synaptic currents. AMPA receptors have decay times of 1-10ms while NMDA receptors decay over 50-150ms. GABA-A decays over 10-40ms. Decay time determines integration window and temporal filtering. Slow decay enables temporal summation while fast decay provides precise timing.",
      "rdfs:domain": {
        "@id": "ns:Synapse"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasMagnitude",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has plasticity magnitude",
      "rdfs:comment": "This property quantifies the magnitude of synaptic plasticity as percentage change or fold change. LTP can increase strengths by 50-200% while LTD decreases by 30-60%. Plasticity magnitude depends on induction protocol, prior state, and developmental stage. Large magnitude enables rapid learning but risks instability.",
      "rdfs:domain": {
        "@id": "ns:SynapticPlasticity"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:hasInductionTime",
      "@type": "owl:DatatypeProperty",
      "rdfs:label": "has induction time",
      "rdfs:comment": "This property specifies the time required to induce plasticity. Brief protocols (<1s) can induce LTP or LTD while longer protocols (minutes) induce late-phase plasticity requiring protein synthesis. Spike-timing protocols use single pairs repeated at low frequency. Short induction times enable rapid learning while longer times may ensure stability.",
      "rdfs:domain": {
        "@id": "ns:SynapticPlasticity"
      },
      "rdfs:range": {
        "@id": "xsd:float"
      }
    },
    {
      "@id": "ns:FastSpikingInterneuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:BasketCell"
      ],
      "rdfs:label": "Fast-Spiking Interneuron",
      "rdfs:comment": "Fast-spiking interneurons fire narrow action potentials at high frequencies (>200 Hz) with minimal adaptation. They express parvalbumin and provide perisomatic inhibition to pyramidal cells. FS cells generate gamma oscillations, regulate excitability, and define temporal windows for integration. They have fast membrane time constants enabling rapid signaling."
    },
    {
      "@id": "ns:RegularSpikingNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:PyramidalNeuron"
      ],
      "rdfs:label": "Regular-Spiking Neuron",
      "rdfs:comment": "Regular-spiking neurons fire with spike frequency adaptation due to calcium-activated potassium currents and M-currents. They are typical of cortical pyramidal cells in superficial layers. RS neurons integrate inputs over ~20ms time constants and show modest adaptation during sustained stimulation. They contrast with intrinsically bursting and fast-spiking types."
    },
    {
      "@id": "ns:IntrinsicallyBurstingNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:PyramidalNeuron"
      ],
      "rdfs:label": "Intrinsically Bursting Neuron",
      "rdfs:comment": "Intrinsically bursting neurons fire bursts of action potentials riding on slow calcium spikes. They are found in cortical layer 5 and thalamus. Bursts enable reliable transmission, enhance synaptic plasticity, and may bind information across time. Bursting arises from dendritic calcium currents amplifying somatic sodium spikes."
    },
    {
      "@id": "ns:ChatteringNeuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Chattering Neuron",
      "rdfs:comment": "Chattering neurons fire high-frequency bursts at gamma frequency (30-70 Hz) in response to suprathreshold stimuli. Found in superficial cortical layers, they may contribute to gamma oscillations and synchronization. Chattering involves fast sodium and delayed rectifier potassium currents enabling rapid repetitive firing within bursts."
    },
    {
      "@id": "ns:LowThresholdSpikingInterneuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Interneuron"
      ],
      "rdfs:label": "Low-Threshold Spiking Interneuron",
      "rdfs:comment": "Low-threshold spiking interneurons express somatostatin and target dendrites of pyramidal cells. They exhibit rebound bursts from hyperpolarization due to T-type calcium channels. LTS cells regulate dendritic integration, plasticity, and inputs. They contrast with fast-spiking basket cells in morphology, targets, and dynamics."
    },
    {
      "@id": "ns:IrregularSpikingInterneuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Interneuron"
      ],
      "rdfs:comment": "Irregular-spiking interneurons show variable interspike intervals and may skip or stutter during current injection. They express VIP or calretinin and often inhibit other interneurons (disinhibition). IS cells contribute to circuit flexibility and state-dependent processing. Their irregular firing reflects complex intrinsic dynamics.",
      "rdfs:label": "Irregular-Spiking Interneuron"
    },
    {
      "@id": "ns:AdaptingInterneuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:Interneuron"
      ],
      "rdfs:label": "Adapting Interneuron",
      "rdfs:comment": "Adapting interneurons show pronounced spike-frequency adaptation during sustained input due to calcium-activated potassium currents. They provide feedback inhibition that weakens over time enabling transient responses. Adaptation creates temporal filtering and gain control. Different interneuron types show varying degrees of adaptation."
    },
    {
      "@id": "ns:NonAdaptingInterneuron",
      "@type": [
        "owl:NamedIndividual",
        "ns:BasketCell"
      ],
      "rdfs:label": "Non-Adapting Interneuron",
      "rdfs:comment": "Non-adapting interneurons fire sustained high-frequency trains with minimal adaptation. Fast-spiking basket cells are typically non-adapting enabling persistent inhibition. Non-adaptation requires weak calcium-activated currents and strong potassium conductances maintaining repolarization. This enables tonic inhibitory control and rhythm generation."
    },
    {
      "@id": "ns:BinocularDisparity",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Binocular Disparity",
      "rdfs:comment": "Binocular disparity is the difference in image positions between the two eyes providing a cue for stereoscopic depth. Disparity-selective neurons in V1 and MT encode depth through tuned responses to specific disparities. Population responses represent three-dimensional scene structure. Disparity processing requires matching corresponding features between eyes."
    },
    {
      "@id": "ns:MotionParallax",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Motion Parallax",
      "rdfs:comment": "Motion parallax provides depth information from relative motion during observer movement - near objects move faster than far objects. Processing involves integration of motion signals with extra-retinal signals about head/eye movements. Neurons in MST may combine optic flow with self-motion signals for navigation and depth perception."
    },
    {
      "@id": "ns:TexturGradient",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Texture Gradient",
      "rdfs:comment": "Texture gradients are systematic variations in texture element size, density, or orientation signaling surface slant and distance. Visual cortex neurons sensitive to texture statistics and spatial frequency gradients may encode surface layout. Texture processing involves filtering, segmentation, and integration of local texture elements into global surface representations."
    },
    {
      "@id": "ns:StructureFromMotion",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Structure from Motion",
      "rdfs:comment": "Structure from motion recovers three-dimensional structure from motion of two-dimensional projections. Kinetic depth effect demonstrates perception of rotating objects from moving dots. Neural mechanisms integrate motion vectors across views to infer 3D shape. Areas MT and MST contribute to structure-from-motion perception with neurons signaling 3D shape."
    },
    {
      "@id": "ns:VisualIllusion",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Visual Illusion",
      "rdfs:comment": "Visual illusions reveal principles of visual processing where perception deviates from physical reality. They demonstrate contextual influences, priors, and inference processes. Examples include brightness illusions from spatial context, motion aftereffects from adaptation, and size illusions from perspective cues. Illusions constrain models of visual computation."
    },
    {
      "@id": "ns:MotionAftereffect",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotionDetection"
      ],
      "rdfs:label": "Motion Aftereffect",
      "rdfs:comment": "Motion aftereffect is illusory motion in the opposite direction following prolonged viewing of moving stimuli. It results from adaptation of motion detectors creating imbalance between opponent directions. MAE demonstrates neural representation of motion through opponent channels. Duration depends on adaptation time and reflects slow recovery of adapted neurons."
    },
    {
      "@id": "ns:FlashLagEffect",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Flash-Lag Effect",
      "rdfs:comment": "Flash-lag effect is the perceived position lag of a flashed object relative to a continuously moving object presented simultaneously. It may reflect motion extrapolation compensating for neural delays or differential latencies for transients versus motion. The effect demonstrates predictive processing in visual motion perception."
    },
    {
      "@id": "ns:ApertrueProblem",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotionDetection"
      ],
      "rdfs:label": "Aperture Problem",
      "rdfs:comment": "The aperture problem arises when motion of a contour viewed through a limited aperture is ambiguous - only motion perpendicular to the contour is detected. Global motion perception requires integration across apertures. MT neurons integrate motion signals solving the aperture problem. End-stopped or corner-sensitive cells provide unambiguous motion signals."
    },
    {
      "@id": "ns:PlaidMotion",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotionDetection"
      ],
      "rdfs:label": "Plaid Motion",
      "rdfs:comment": "Plaid motion perception from overlapping gratings tests integration of component motions. Plaids can appear to slide or cohere depending on relative orientations and speeds. MT neurons shift from component to pattern responses suggesting neural basis of motion integration. Vector averaging and intersection-of-constraints models account for plaid perception."
    },
    {
      "@id": "ns:BiologicalMotion",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotionDetection"
      ],
      "rdfs:comment": "Biological motion refers to characteristic motion patterns of living organisms recognizable from point lights attached to joints. Superior temporal sulcus contains neurons selective for biological motion. Perception is remarkably fast and robust suggesting specialized mechanisms. Biological motion processing supports action recognition, intention understanding, and social perception.",
      "rdfs:label": "Biological Motion"
    },
    {
      "@id": "ns:OpticFlow",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotionDetection"
      ],
      "rdfs:label": "Optic Flow",
      "rdfs:comment": "Optic flow is the pattern of motion on the retina during self-motion. Expansion indicates forward motion, contraction indicates backward motion, and rotation indicates turning. MST neurons are selective for optic flow components. Optic flow supports navigation, posture control, and estimating time-to-contact. Decomposition into translation and rotation enables heading estimation."
    },
    {
      "@id": "ns:ColorConstancy",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Color Constancy",
      "rdfs:comment": "Color constancy maintains stable color perception despite changes in illumination. The visual system discounts illuminant color through comparison of surfaces. V4 neurons show partial color constancy with responses less affected by illumination than photoreceptors. Constancy involves assumptions about lighting, spatial comparisons, and possible memory colors."
    },
    {
      "@id": "ns:ContourIntegration",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Contour Integration",
      "rdfs:comment": "Contour integration links local edge segments into global contours using gestalt principles like continuity and proximity. V1 and V2 neurons show enhanced responses for contours versus isolated elements through long-range horizontal connections. Contour integration enables figure-ground segregation and object segmentation. It demonstrates importance of context in visual processing."
    },
    {
      "@id": "ns:FigureGroundSegregation",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Figure-Ground Segregation",
      "rdfs:comment": "Figure-ground segregation distinguishes objects from backgrounds using cues like convexity, symmetry, size, and surroundedness. Neurons in V1, V2, and higher areas show enhanced responses for figure versus ground. Segmentation involves recurrent processing and attention. Figure-ground assignment is ambiguous in some stimuli demonstrating active perceptual organization."
    },
    {
      "@id": "ns:PerceptualGrouping",
      "@type": [
        "owl:NamedIndividual",
        "ns:VisualCortex"
      ],
      "rdfs:label": "Perceptual Grouping",
      "rdfs:comment": "Perceptual grouping organizes visual elements into coherent structures using gestalt principles like similarity, proximity, common fate, and closure. Grouping operates preattentively and automatically. Neural correlates include synchronized firing of neurons representing grouped elements and enhanced responses in extrastriate cortex. Grouping is fundamental for scene understanding and object recognition."
    },
    {
      "@id": "ns:SomatosensoryCorex",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Somatosensory Cortex",
      "rdfs:comment": "Somatosensory cortex processes touch, proprioception, and pain organized somatotopically in homunculus. Primary somatosensory cortex (S1) contains four areas with distinct receptive field properties. S1 represents texture, shape, and vibration frequency. Hierarchical processing extracts increasingly complex tactile features supporting object recognition by touch."
    },
    {
      "@id": "ns:AuditoryCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Auditory Cortex",
      "rdfs:comment": "Auditory cortex processes sound organized tonotopically with neurons tuned to frequency, amplitude, and temporal patterns. Primary auditory cortex (A1) represents spectrotemporal features while belt and parabelt areas extract complex auditory objects like speech and music. Hierarchical processing builds invariance to pitch, location, and timing. Auditory streams segregate concurrent sounds."
    },
    {
      "@id": "ns:OlfactoryCortex",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Olfactory Cortex",
      "rdfs:comment": "Olfactory cortex processes odor information from olfactory bulb without thalamic relay. Piriform cortex implements pattern completion for odor recognition using distributed representations. Orbitofrontal cortex represents odor identity and hedonic value. Olfactory processing involves oscillations, sparsification, and associative learning. Odors trigger strong memory and emotional associations."
    },
    {
      "@id": "ns:GustatoryCorrtex",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Gustatory Cortex",
      "rdfs:comment": "Gustatory cortex in insula and frontal operculum processes taste. Primary gustatory cortex represents basic tastes (sweet, salty, sour, bitter, umami). Secondary gustatory cortex in orbitofrontal cortex represents flavor combining taste, smell, and texture and encodes hedonic value. Taste processing involves learning taste-consequence associations."
    },
    {
      "@id": "ns:VestibularSystem",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Vestibular System",
      "rdfs:comment": "Vestibular system processes head motion and gravity for balance, posture, and spatial orientation. Semicircular canals detect rotation while otoliths detect linear acceleration. Vestibular nuclei integrate vestibular, visual, and proprioceptive signals. Vestibular signals update head direction and contribute to path integration, spatial navigation, and self-motion perception."
    },
    {
      "@id": "ns:MultisenssoryIntegration",
      "@type": [
        "owl:NamedIndividual",
        "ns:SensoryProcessing"
      ],
      "rdfs:label": "Multisensory Integration",
      "rdfs:comment": "Multisensory integration combines information from multiple senses following optimal integration principles. Superior colliculus integrates auditory, visual, and somatosensory information for orienting. Multisensory neurons show enhanced responses to congruent stimuli. Integration involves causal inference determining whether signals originate from same source. Optimal integration weights cues by reliability."
    },
    {
      "@id": "ns:MotorLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Motor Learning",
      "rdfs:comment": "Motor learning improves motor performance through practice involving cerebellum and motor cortex. Adaptation corrects systematic errors using sensory prediction errors. Sequence learning enables skilled movements. Reinforcement learning selects successful actions. Consolidation transfers skill from explicit to implicit representations. Multiple motor memory systems support different aspects of learning."
    },
    {
      "@id": "ns:AdaptationLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Adaptation Learning",
      "rdfs:comment": "Motor adaptation adjusts movements to compensate for perturbations or changed dynamics. Adaptation is driven by sensory prediction errors - mismatch between predicted and actual sensory feedback. Cerebellum learns internal models through climbing fiber error signals. Adaptation exhibits savings - faster relearning after washout, suggesting retention of adapted state."
    },
    {
      "@id": "ns:SkillLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Skill Learning",
      "rdfs:comment": "Skill learning improves speed and accuracy of complex movement sequences through practice. It involves motor cortex, basal ganglia, and cerebellum. Early learning requires attention and cognitive control while later stages become automatic and habitual. Motor cortex representations expand during learning. Consolidation stabilizes skills and enables offline learning during sleep."
    },
    {
      "@id": "ns:SequenceLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Sequence Learning",
      "rdfs:comment": "Sequence learning acquires motor sequences chunking elementary actions into fluent behaviors. Basal ganglia and motor cortex reorganize to represent sequence chunks. Sequential dependencies are learned explicitly and implicitly. Sequence-selective neurons emerge in motor cortex and striatum. Disrupting sequences reveals hierarchical organization with super-ordinate and sub-ordinate sequence elements."
    },
    {
      "@id": "ns:UseDependentLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:MotorCortex"
      ],
      "rdfs:label": "Use-Dependent Learning",
      "rdfs:comment": "Use-dependent learning biases movements toward frequently executed directions or patterns through motor cortex plasticity. Repetition without explicit reinforcement gradually shifts movement trajectories. This demonstrates that simple motor execution, not just reward or errors, drives plasticity. Use-dependent learning may contribute to motor habits and consolidate adaptations."
    },
    {
      "@id": "ns:SensoriomotorAdaptation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Sensorimotor Adaptation",
      "rdfs:comment": "Sensorimotor adaptation adjusts mappings between sensory inputs and motor outputs when perturbations change input-output relationships. Examples include prism adaptation shifting visual field and force field adaptation to novel dynamics. Adaptation involves recalibration of internal models. Generalization patterns reveal coordinate frames and representations used for adaptation."
    },
    {
      "@id": "ns:VisuomotorAdaptation",
      "@type": [
        "owl:NamedIndividual",
        "ns:Cerebellum"
      ],
      "rdfs:label": "Visuomotor Adaptation",
      "rdfs:comment": "Visuomotor adaptation adjusts visually guided reaching when visual feedback is perturbed. Prism goggles laterally displacing vision induce adaptive shifts correcting pointing errors. Rotation perturbations require relearning visuomotor transformations. Adaptation exhibits aftereffects when perturbation is removed. Cerebellum and posterior parietal cortex contribute to visuomotor adaptation."
    },
    {
      "@id": "ns:ImplicitLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:MachineLearning"
      ],
      "rdfs:label": "Implicit Learning",
      "rdfs:comment": "Implicit learning acquires knowledge without conscious awareness or intention to learn. Examples include motor skills, artificial grammar, and statistical regularities. Implicit learning involves basal ganglia and cerebellum contrasting with explicit hippocampal learning. Implicit knowledge is hard to verbalize but guides behavior. Dual-process theories distinguish implicit and explicit learning systems."
    },
    {
      "@id": "ns:ProceduralMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:WorkingMemory"
      ],
      "rdfs:label": "Procedural Memory",
      "rdfs:comment": "Procedural memory stores how to perform skills and procedures acquired gradually through repetition. It is implicit, accessed through performance rather than recall, and involves basal ganglia and cerebellum. Procedural learning is preserved in amnesia demonstrating independence from declarative memory. Examples include motor skills, perceptual skills, and cognitive skills."
    },
    {
      "@id": "ns:DeclarativeMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Declarative Memory",
      "rdfs:comment": "Declarative memory stores facts and events accessible to conscious recall requiring hippocampus and medial temporal lobe. It includes episodic memory for events and semantic memory for facts. Declarative memory is flexible, rapidly acquired, and easily communicated. It contrasts with implicit procedural memory. Consolidation transfers declarative memories to neocortex."
    },
    {
      "@id": "ns:SemanticMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Semantic Memory",
      "rdfs:comment": "Semantic memory stores general knowledge about facts, concepts, and meanings independent of personal experience. It includes knowledge of objects, words, and associations. Semantic representations in temporal and frontal cortex abstract from specific episodes. Semantic memory can be preserved when episodic memory is impaired. Some semantic knowledge may consolidate from episodic experiences."
    },
    {
      "@id": "ns:FamiliarityMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Familiarity Memory",
      "rdfs:comment": "Familiarity is the sense that an item has been previously encountered without recollection of contextual details. It supports recognition memory along with recollection. Perirhinal cortex mediates familiarity through stimulus-specific adaptation or plasticity. Familiarity is faster than recollection and more resistant to aging and hippocampal damage. Dual-process models distinguish familiarity and recollection."
    },
    {
      "@id": "ns:RecollectionMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Recollection Memory",
      "rdfs:comment": "Recollection retrieves episodic details and context accompanying recognition. It depends on hippocampus implementing pattern completion. Recollection provides rich contextual details and sense of remembering versus knowing. It is slower than familiarity, more affected by hippocampal damage, and shows distinct neural signatures. Recollection supports source memory and temporal order memory."
    },
    {
      "@id": "ns:SourceMemory",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Source Memory",
      "rdfs:comment": "Source memory remembers contextual details of when, where, and how information was acquired. It depends on hippocampus and prefrontal cortex binding items to contexts. Source memory declines with age and prefrontal damage. It is tested by asking where or when items were presented. Source memory demonstrates episodic character of hippocampal memory."
    },
    {
      "@id": "ns:Consolidation",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Memory Consolidation",
      "rdfs:comment": "Consolidation stabilizes memories over time through synaptic and systems-level processes. Synaptic consolidation over hours involves protein synthesis and structural changes. Systems consolidation over weeks to years transfers memories from hippocampus to neocortex. Reactivation during sleep supports consolidation. Disrupting consolidation causes retrograde amnesia. Reconsolidation restabilizes reactivated memories."
    },
    {
      "@id": "ns:Reconsolidation",
      "@type": [
        "owl:NamedIndividual",
        "ns:EpisodicMemory"
      ],
      "rdfs:label": "Reconsolidation",
      "rdfs:comment": "Reconsolidation restabilizes memories after retrieval-induced destabilization. Retrieved memories enter labile state requiring protein synthesis to restabilize. Reconsolidation enables memory updating and strengthening but also creates vulnerability to interference. It demonstrates memories are not static but dynamically maintained. Reconsolidation has clinical implications for modifying traumatic memories."
    },
    {
      "@id": "ns:Extinction",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Extinction",
      "rdfs:comment": "Extinction is decline in conditioned response when conditioned stimulus is no longer followed by unconditioned stimulus. It represents new learning that inhibits rather than erases original associations. Extinction is context-dependent showing renewal when context changes. Spontaneous recovery demonstrates original memory persists. Extinction involves prefrontal cortex inhibiting amygdala responses."
    },
    {
      "@id": "ns:Generalization",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Generalization",
      "rdfs:comment": "Generalization transfers learning to new stimuli or contexts similar to trained conditions. Generalization gradients reflect similarity between test and trained stimuli. Appropriate generalization enables using experience in novel situations while excessive generalization causes overgeneralization. Similarity representations in neural codes determine generalization. Generalization can be adaptive or maladaptive as in anxiety disorders."
    },
    {
      "@id": "ns:Discrimination",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Discrimination Learning",
      "rdfs:comment": "Discrimination learning distinguishes similar stimuli associated with different outcomes. It requires learning which features predict outcomes. Discrimination training sharpens neural representations through competitive learning and attention. Discrimination creates categorical boundaries and can enhance perceptual sensitivity. It contrasts with generalization reflecting exploration-exploitation tradeoff."
    },
    {
      "@id": "ns:CategorizationLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Categorization Learning",
      "rdfs:comment": "Categorization assigns stimuli to discrete categories based on rules, prototypes, or exemplars. It can be rule-based (prefrontal cortex) or similarity-based (striatum). Category learning sharpens within-category similarity and between-category differences. Categorical perception creates sharp boundaries despite continuous variation. Categorization is fundamental for object recognition and concept learning."
    },
    {
      "@id": "ns:PerceptualLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Perceptual Learning",
      "rdfs:comment": "Perceptual learning improves perceptual discrimination through practice. It enhances sensitivity, reduces thresholds, and can be highly specific to trained stimuli and tasks. Mechanisms include attention-weighted learning, selective routing, and modified early sensory representations. Perceptual learning demonstrates plasticity in adult sensory cortex and has clinical applications for treating amblyopia and other deficits."
    },
    {
      "@id": "ns:StatisticalLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Statistical Learning",
      "rdfs:comment": "Statistical learning extracts regularities from sequences and distributions through implicit processes. Infants and adults detect statistical patterns in speech, vision, and other modalities. Statistical learning occurs rapidly, automatically, and across sensory modalities. It may involve prediction error signals and Bayesian inference. Statistical learning supports language acquisition and environmental adaptation."
    },
    {
      "@id": "ns:ErrorCorrectionLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Error-Correction Learning",
      "rdfs:comment": "Error-correction learning adjusts parameters to reduce errors between actual and desired outputs. Supervised learning algorithms like delta rule and backpropagation implement error-correction. In cerebellum, climbing fibers signal errors driving Purkinje cell plasticity. Error-correction enables accurate learned behaviors but requires teaching signals. It contrasts with Hebbian correlation-based learning."
    },
    {
      "@id": "ns:UnsupervisedLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Unsupervised Learning",
      "rdfs:comment": "Unsupervised learning discovers structure in data without explicit labels or feedback. Hebbian learning, sparse coding, and predictive coding are unsupervised. Unsupervised learning forms internal representations capturing statistical regularities. It explains development of receptive fields, topographic maps, and dimensionality reduction. Biological learning combines unsupervised and supervised mechanisms."
    },
    {
      "@id": "ns:CompetitiveLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:HebbianLearning"
      ],
      "rdfs:label": "Competitive Learning",
      "rdfs:comment": "Competitive learning uses winner-take-all dynamics where most active neurons learn from inputs while others are suppressed. It forms sparse codes and topographic maps. Competition can be local or global. Self-organizing maps use competitive learning with neighborhood cooperation. Competition emerges from lateral inhibition or normalization. Competitive learning clusters inputs and forms categorical representations."
    },
    {
      "@id": "ns:OneShotLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "One-Shot Learning",
      "rdfs:comment": "One-shot learning forms memories from single experiences requiring rapid synaptic plasticity and pattern separation. Hippocampus implements one-shot learning for episodes. Rapid NMDA receptor-dependent plasticity enables quick encoding. One-shot learning contrasts with gradual statistical learning but can cause false memories. Sparse representations and separated patterns prevent interference."
    },
    {
      "@id": "ns:TransferLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Transfer Learning",
      "rdfs:comment": "Transfer learning applies knowledge from one task or domain to facilitate learning new related tasks. Positive transfer accelerates learning while negative transfer interferes. Transfer depends on similarity of tasks and abstraction of learned representations. Humans show remarkable transfer suggesting abstract representations. Transfer is key challenge for artificial intelligence matching human flexibility."
    },
    {
      "@id": "ns:MetaLearning",
      "@type": [
        "owl:NamedIndividual",
        "ns:LearningRule"
      ],
      "rdfs:label": "Meta-Learning",
      "rdfs:comment": "Meta-learning is learning to learn - acquiring strategies and representations that facilitate future learning. It enables rapid adaptation to new tasks using prior experience. Meta-learning may involve prefrontal cortex learning task structure and strategies. Few-shot learning through meta-training enables learning from minimal examples. Meta-learning connects to cognitive control and transfer learning."
    },
    {
      "@id": "ns:CreditAssignment",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Credit Assignment",
      "rdfs:comment": "Credit assignment determines which actions or representations deserve credit for outcomes. Temporal credit assignment spans delays between actions and outcomes through eligibility traces or temporal difference learning. Structural credit assignment through networks uses backpropagation or feedback connections. Credit assignment is fundamental challenge for learning in complex environments with delayed rewards."
    },
    {
      "@id": "ns:EligibilityTrace",
      "@type": [
        "owl:NamedIndividual",
        "ns:ReinforcementLearning"
      ],
      "rdfs:label": "Eligibility Trace",
      "rdfs:comment": "Eligibility traces tag recently active synapses as eligible for modification when rewards arrive. They solve temporal credit assignment for delayed rewards by bridging temporal gaps. Traces decay exponentially with time constant determining credit distribution. Eligibility traces may be implemented by biochemical signals, sustained activity, or synaptic tags. They enable efficient learning with sparse delayed rewards."
    },
    {
      "@id": "ns:NeuralDarwinism",
      "@type": [
        "owl:NamedIndividual",
        "ns:TheoreticalNeuroscience"
      ],
      "rdfs:label": "Neural Darwinism",
      "rdfs:comment": "Neural Darwinism proposes brain development and function follow selection principles similar to evolution. Neural groups compete for inputs and survival based on correlations with reentrant signals. Selection shapes connectivity during development and experience. Theory emphasizes degeneracy, reentrant signaling, and value systems. Neural Darwinism offers framework for understanding brain development and consciousness."
    },
    {
      "@id": "ns:GlobalWorkspace",
      "@type": [
        "owl:NamedIndividual",
        "ns:TheoreticalNeuroscience"
      ],
      "rdfs:label": "Global Workspace Theory",
      "rdfs:comment": "Global workspace theory proposes consciousness arises when information is globally broadcast to multiple brain systems. Unconscious processing is modular and local while conscious processing involves widespread activation. Prefrontal and parietal cortex implement global workspace enabling flexible integration and reportability. Theory explains access consciousness and integration of information. Neural signatures include widespread activation and gamma synchronization."
    },
    {
      "@id": "ns:IntegratedInformation",
      "@type": [
        "owl:NamedIndividual",
        "ns:TheoreticalNeuroscience"
      ],
      "rdfs:label": "Integrated Information Theory",
      "rdfs:comment": "Integrated information theory proposes consciousness corresponds to integrated information (Phi) in a system. High Phi requires both differentiation and integration - the system must be irreducible to independent components. Theory derives from axioms about conscious experience. It predicts cortex has high Phi while cerebellum despite many neurons has low Phi. IIT offers mathematical framework for consciousness."
    },
    {
      "@id": "ns:AdaptiveCoding",
      "@type": [
        "owl:NamedIndividual",
        "ns:EfficientCoding"
      ],
      "rdfs:label": "Adaptive Coding",
      "rdfs:comment": "Adaptive coding adjusts neural representations to match stimulus statistics. Adaptation whitens inputs, adjusts gain, and reallocates coding resources to informative dimensions. Rapid adaptation occurs through short-term mechanisms while long-term adaptation involves developmental plasticity. Adaptive coding optimizes information transmission given constraints. It explains why sensory systems adapt to context."
    },
    {
      "@id": "ns:RedundancyReduction",
      "@type": [
        "owl:NamedIndividual",
        "ns:EfficientCoding"
      ],
      "rdfs:label": "Redundancy Reduction",
      "rdfs:comment": "Redundancy reduction removes correlations in representations to avoid wasting coding resources on predictable information. Early sensory processing whitens natural signals through center-surround filtering. Redundancy reduction increases entropy and capacity. It is a principle of efficient coding. Barlow proposed retina implements redundancy reduction. However, some redundancy enables error correction."
    },
    {
      "@id": "ns:PredictiveCodingPrinciple",
      "@type": [
        "owl:NamedIndividual",
        "ns:TheoreticalNeuroscience"
      ],
      "rdfs:label": "Predictive Coding Principle",
      "rdfs:comment": "Predictive coding proposes neural systems predict inputs and transmit only prediction errors. This implements efficient coding by not wasting resources on predictable information. Hierarchical predictive coding combines bottom-up errors with top-down predictions implementing Bayesian inference. Theory unifies perception, action, and learning under prediction error minimization. It explains attention, priors, and precision weighting."
    },
    {
      "@id": "ns:PrincipalComponentAnalysis",
      "@type": [
        "owl:NamedIndividual",
        "ns:UnsupervisedLearning"
      ],
      "rdfs:label": "Principal Component Analysis",
      "rdfs:comment": "Principal component analysis finds directions of maximum variance in data for dimensionality reduction. PCA decorrelates signals and compresses information. Oja's learning rule performs PCA extracting principal component. PCA explains development of receptive fields as independent components. It is unsupervised, linear, and optimal for Gaussian data. PCA provides normative theory for sensory coding."
    },
    {
      "@id": "ns:IndependentComponentAnalysis",
      "@type": [
        "owl:NamedIndividual",
        "ns:UnsupervisedLearning"
      ],
      "rdfs:label": "Independent Component Analysis",
      "rdfs:comment": "Independent component analysis finds statistically independent sources from mixed signals. ICA extracts non-Gaussian independent components. Applied to natural images, ICA learns filters resembling V1 simple cell receptive fields. ICA suggests sensory systems learn independent causes of sensory signals. It goes beyond decorrelation (PCA) to find higher-order structure. ICA is a powerful unsupervised learning principle."
    },
    {
      "@id": "ns:NonnegativeMatrixFactorization",
      "@type": [
        "owl:NamedIndividual",
        "ns:UnsupervisedLearning"
      ],
      "rdfs:label": "Nonnegative Matrix Factorization",
      "rdfs:comment": "Nonnegative matrix factorization decomposes data into nonnegative parts-based representations. It learns sparse, localized features suitable for object parts. NMF applied to faces learns parts like eyes, nose. The nonnegativity constraint creates sparse additive representations matching neural firing constraints. NMF may explain parts-based representations in visual cortex."
    },
    {
      "@id": "ns:SlowFeaturelAnalysis",
      "@type": [
        "owl:NamedIndividual",
        "ns:UnsupervisedLearning"
      ],
      "rdfs:label": "Slow Feature Analysis",
      "rdfs:comment": "Slow feature analysis extracts slowly varying features from rapidly varying sensory signals. It exploits temporal continuity that object identity varies slowly despite rapid view changes. SFA can learn invariant representations including position-invariant and head-direction cells. Slowness is unsupervised learning principle exploiting temporal structure. SFA relates to trace learning rules for invariance."
    },
    {
      "@id": "ns:VariationalAutoencoder",
      "@type": [
        "owl:NamedIndividual",
        "ns:DeepLearning"
      ],
      "rdfs:label": "Variational Autoencoder",
      "rdfs:comment": "Variational autoencoders learn probabilistic latent representations by encoding inputs to distributions and decoding samples. They optimize variational lower bound on data likelihood. VAEs learn disentangled representations capturing independent factors. They generate new samples by sampling latent space. VAEs connect deep learning to probabilistic inference and may relate to hierarchical Bayesian brain theories."
    },
    {
      "@id": "ns:GenerativeAdversarialNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:DeepLearning"
      ],
      "rdfs:label": "Generative Adversarial Network",
      "rdfs:comment": "Generative adversarial networks learn to generate realistic data through adversarial training of generator and discriminator networks. Generator creates samples while discriminator judges authenticity. GANs produce impressive image synthesis but training is unstable. They may relate to predictive coding where generator predicts inputs. GANs demonstrate power of adversarial learning."
    },
    {
      "@id": "ns:RecurrentNeuralNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:RecurrentNetwork"
      ],
      "rdfs:label": "Recurrent Neural Network",
      "rdfs:comment": "Recurrent neural networks process sequences with feedback connections enabling temporal dynamics. RNNs maintain hidden state capturing sequence history. LSTMs and GRUs use gating to mitigate vanishing gradients. RNNs can generate sequences and learn complex dynamics. They model language, speech, and time series. RNNs relate to recurrent cortical networks though differ in architecture and learning."
    },
    {
      "@id": "ns:TransformerNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:DeepLearning"
      ],
      "rdfs:label": "Transformer Network",
      "rdfs:comment": "Transformers process sequences using attention mechanisms without recurrence. Self-attention computes context-dependent representations attending to all positions. Transformers parallelize sequence processing and capture long-range dependencies. They achieve state-of-the-art language modeling. Transformers demonstrate power of attention and may relate to working memory and prefrontal function though biological implementation differs."
    },
    {
      "@id": "ns:AttentionMechanism",
      "@type": [
        "owl:NamedIndividual",
        "ns:DeepLearning"
      ],
      "rdfs:label": "Attention Mechanism in ML",
      "rdfs:comment": "Attention mechanisms in machine learning selectively weight inputs based on relevance. They enable flexible routing of information and long-range dependencies. Attention is differentiable and learned end-to-end. While inspired by biological attention, implementations differ - biological attention involves top-down modulation while ML attention is computed from inputs. Comparing artificial and biological attention reveals principles of selective processing."
    },
    {
      "@id": "ns:ResidualNetwork",
      "@type": [
        "owl:NamedIndividual",
        "ns:ConvolutionalNeuralNetwork"
      ],
      "rdfs:label": "Residual Network",
      "rdfs:comment": "Residual networks use skip connections allowing gradients to flow directly through many layers enabling very deep networks. Residual connections create identity mappings and may implement iterative refinement. ResNets achieve excellent image classification. Skip connections relate to feedback connections in cortex and recurrent processing. Both enable deeper computation while maintaining gradients."
    },
    {
      "@id": "ns:BatchNormalization",
      "@type": [
        "owl:NamedIndividual",
        "ns:DeepLearning"
      ],
      "rdfs:label": "Batch Normalization",
      "rdfs:comment": "Batch normalization normalizes activations across mini-batches reducing internal covariate shift and enabling faster training. It acts as regularizer and allows higher learning rates. Batch norm's success is not fully understood theoretically. It may relate to biological normalization mechanisms. Both use divisive normalization but biological normalization operates locally in real-time while batch norm uses batch statistics."
    },
    {
      "@id": "ns:SynapticVesicle",
      "@type": [
        "owl:NamedIndividual",
        "ns:Synapse"
      ],
      "rdfs:label": "Synaptic Vesicle",
      "rdfs:comment": "Synaptic vesicles are membrane-bound organelles storing neurotransmitters in presynaptic terminals. They undergo exocytosis triggered by calcium influx releasing transmitters into the synaptic cleft. Vesicle pools include readily releasable, recycling, and reserve pools. Vesicle dynamics determine short-term plasticity and reliability of transmission."
    },
    {
      "@id": "ns:ActiveZone",
      "@type": [
        "owl:NamedIndividual",
        "ns:Synapse"
      ],
      "rdfs:label": "Active Zone",
      "rdfs:comment": "The active zone is the presynaptic specialization where vesicles dock and fuse. It contains proteins organizing calcium channels near release sites. Active zone structure determines release probability and spatial precision of transmission. Electron microscopy and super-resolution imaging reveal active zone organization."
    },
    {
      "@id": "ns:PostsynapticDensity",
      "@type": [
        "owl:NamedIndividual",
        "ns:Synapse"
      ],
      "rdfs:label": "Postsynaptic Density",
      "rdfs:comment": "The postsynaptic density is a protein-rich structure anchoring receptors and signaling molecules at excitatory synapses. It organizes receptor trafficking, anchors scaffolding proteins, and couples receptors to downstream signaling. PSD composition changes with plasticity. Mass spectrometry reveals hundreds of PSD proteins."
    },
    {
      "@id": "ns:DendriticSpine",
      "@type": [
        "owl:NamedIndividual",
        "ns:Dendrite"
      ],
      "rdfs:label": "Dendritic Spine",
      "rdfs:comment": "Dendritic spines are small protrusions on dendrites receiving most excitatory synapses in cortex and hippocampus. They compartmentalize calcium and biochemical signals. Spine morphology correlates with synaptic strength. Spine dynamics reflect structural plasticity with spines appearing and disappearing with learning."
    },
    {
      "@id": "ns:AxonInitialSegment",
      "@type": [
        "owl:NamedIndividual",
        "ns:Axon"
      ],
      "rdfs:label": "Axon Initial Segment",
      "rdfs:comment": "The axon initial segment is where action potentials initiate due to high sodium channel density. It is a specialized region between soma and myelinated axon. AIS position and length are plastic, regulating excitability. AIS structure is maintained by ankyrin-G and other scaffolding proteins."
    },
    {
      "@id": "ns:MyelinSheath",
      "@type": [
        "owl:NamedIndividual",
        "ns:Axon"
      ],
      "rdfs:label": "Myelin Sheath",
      "rdfs:comment": "Myelin is insulating membrane wrapping axons enabling saltatory conduction and increasing conduction velocity. Oligodendrocytes myelinate CNS axons while Schwann cells myelinate PNS. Myelin disruption causes neurological disorders like multiple sclerosis. Activity regulates myelination demonstrating adaptive myelination."
    },
    {
      "@id": "ns:NodeOfRanvier",
      "@type": [
        "owl:NamedIndividual",
        "ns:Axon"
      ],
      "rdfs:label": "Node of Ranvier",
      "rdfs:comment": "Nodes of Ranvier are unmyelinated gaps between myelin segments enriched in sodium channels where action potentials regenerate. Saltatory conduction jumps between nodes increasing speed and efficiency. Node structure is maintained by glial interactions and specialized proteins. Node dysfunction impairs conduction."
    },
    {
      "@id": "ns:Astrocyte",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Astrocyte",
      "rdfs:comment": "Astrocytes are star-shaped glial cells supporting neurons through metabolic support, neurotransmitter uptake, and ion buffering. They ensheath synapses forming tripartite synapses and regulate synaptic transmission. Astrocytes coordinate neural activity through calcium waves and gliotransmitter release. They contribute to blood-brain barrier."
    },
    {
      "@id": "ns:Microglia",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Microglia",
      "rdfs:comment": "Microglia are immune cells of the brain surveilling tissue and responding to injury. They prune synapses during development through complement-mediated phagocytosis. Microglia become activated in disease releasing inflammatory factors. Recent work reveals diverse microglial states and roles in circuit refinement and plasticity."
    },
    {
      "@id": "ns:Oligodendrocyte",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Oligodendrocyte",
      "rdfs:comment": "Oligodendrocytes myelinate multiple CNS axons providing metabolic support and enabling fast conduction. They differentiate from oligodendrocyte precursor cells throughout life. Oligodendrocyte death causes demyelinating diseases. Activity-dependent myelination adapts myelin patterns to circuit function enabling adaptive neural conduction."
    },
    {
      "@id": "ns:BloodBrainBarrier",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Blood-Brain Barrier",
      "rdfs:comment": "The blood-brain barrier restricts passage of molecules from blood to brain protecting neural tissue. It is formed by endothelial tight junctions with support from astrocytes and pericytes. The barrier maintains brain homeostasis but limits drug delivery. Disruption occurs in neurological diseases."
    },
    {
      "@id": "ns:ExtracellularMatrix",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neuron"
      ],
      "rdfs:label": "Extracellular Matrix",
      "rdfs:comment": "The extracellular matrix is a network of proteins and glycans surrounding neurons. Perineuronal nets enwrap fast-spiking interneurons regulating plasticity and closing critical periods. ECM components guide axon growth and synapse formation. Matrix remodeling by proteases enables plasticity in adult brain."
    },
    {
      "@id": "ns:GapJunction",
      "@type": [
        "owl:NamedIndividual",
        "ns:Synapse"
      ],
      "rdfs:label": "Gap Junction",
      "rdfs:comment": "Gap junctions are electrical synapses enabling direct cytoplasmic coupling between neurons through connexin channels. They enable synchronization, fast communication, and bidirectional signaling. Gap junctions connect interneurons promoting gamma oscillations. They are more prevalent than previously thought and regulated by activity and neuromodulators."
    },
    {
      "@id": "ns:Neurogranin",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumBuffer"
      ],
      "rdfs:label": "Neurogranin",
      "rdfs:comment": "Neurogranin is a postsynaptic protein regulating calmodulin availability and calcium signaling. It binds calmodulin in low calcium releasing it when calcium rises. Neurogranin concentrates in dendritic spines regulating LTP and memory. Neurogranin mutations impair synaptic plasticity and are implicated in schizophrenia."
    },
    {
      "@id": "ns:Calmodulin",
      "@type": [
        "owl:NamedIndividual",
        "ns:CalciumBuffer"
      ],
      "rdfs:label": "Calmodulin",
      "rdfs:comment": "Calmodulin is a calcium-binding protein transducing calcium signals by activating downstream targets including kinases and phosphatases. It has four calcium-binding EF-hand motifs. Calmodulin activates CaMKII which phosphorylates AMPA receptors during LTP. Calmodulin is a universal calcium sensor regulating numerous cellular processes."
    },
    {
      "@id": "ns:CaMKII",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "CaMKII",
      "rdfs:comment": "Calcium/calmodulin-dependent protein kinase II is a major postsynaptic kinase essential for LTP. It is activated by calcium-calmodulin and undergoes autophosphorylation maintaining activity after calcium returns to baseline. CaMKII phosphorylates AMPA receptors increasing conductance and promotes receptor insertion. It may store synaptic memory through persistent phosphorylation."
    },
    {
      "@id": "ns:PKA",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "PKA",
      "rdfs:comment": "Protein kinase A is activated by cAMP and phosphorylates many targets including ion channels and transcription factors. PKA is important for late-phase LTP requiring protein synthesis and for neuromodulatory effects. PKA phosphorylates CREB enabling transcription of plasticity-related genes. PKA activity is regulated by G-protein coupled receptors."
    },
    {
      "@id": "ns:PKC",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "PKC",
      "rdfs:comment": "Protein kinase C is activated by calcium and diacylglycerol and has multiple isoforms with distinct functions. PKC phosphorylates receptors, channels, and synaptic proteins. It is implicated in LTP, presynaptic plasticity, and memory. PKC activity maintains increased transmitter release after tetanus. Different PKC isoforms may have opposing effects on plasticity."
    },
    {
      "@id": "ns:CREB",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "CREB",
      "rdfs:comment": "cAMP response element-binding protein is a transcription factor phosphorylated by kinases including PKA and CaMKIV. Phosphorylated CREB drives transcription of plasticity genes and is required for long-term memory and late-phase LTP. CREB regulates expression of BDNF, Arc, and other plasticity-related proteins. CREB is a molecular switch for long-term plasticity."
    },
    {
      "@id": "ns:Arc",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "Arc/Arg3.1",
      "rdfs:comment": "Activity-regulated cytoskeleton-associated protein is an immediate early gene product rapidly induced by activity. Arc is targeted to activated synapses where it regulates AMPA receptor endocytosis and consolidation. Arc knockout impairs LTP consolidation and memory. Arc acts as a link between synaptic activity and long-term changes."
    },
    {
      "@id": "ns:BDNF",
      "@type": [
        "owl:NamedIndividual",
        "ns:SynapticPlasticity"
      ],
      "rdfs:label": "BDNF",
      "rdfs:comment": "Brain-derived neurotrophic factor supports neuronal survival, differentiation, and synaptic plasticity. BDNF is released activity-dependently and binds TrkB receptors activating signaling cascades. BDNF is required for late-phase LTP and long-term memory through transcription and protein synthesis. BDNF regulates dendritic growth, synaptogenesis, and neurotransmitter release."
    },
    {
      "@id": "ns:TrkB",
      "@type": [
        "owl:NamedIndividual",
        "ns:Receptor"
      ],
      "rdfs:label": "TrkB Receptor",
      "rdfs:comment": "Tropomyosin receptor kinase B is the receptor for BDNF activating downstream signaling including MAPK, PI3K, and PLCgamma pathways. TrkB activation promotes survival, growth, and plasticity. TrkB is required for late-phase LTP and memory consolidation. TrkB signaling regulates translation, transcription, and structural plasticity."
    },
    {
      "@id": "ns:NeuropeptideY",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Neuropeptide Y",
      "rdfs:comment": "Neuropeptide Y is released from interneurons and regulates feeding, anxiety, and stress responses. NPY acts through multiple GPCRs with diverse effects. It has anxiolytic and antidepressant effects. NPY is co-released with GABA from specific interneurons. NPY modulates synaptic transmission and excitability."
    },
    {
      "@id": "ns:Substance",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Substance P",
      "rdfs:comment": "Substance P is a neuropeptide involved in pain transmission, inflammation, and mood. It acts through NK1 receptors and is released from sensory neurons and other sites. Substance P antagonists have antidepressant and analgesic effects. It modulates nociception and stress responses."
    },
    {
      "@id": "ns:Oxytocin",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Oxytocin",
      "rdfs:comment": "Oxytocin is a neuropeptide and hormone regulating social behavior, bonding, trust, and reproduction. It is synthesized in hypothalamus and released from posterior pituitary and brain sites. Oxytocin acts through GPCR receptors modulating neural circuits for social cognition. It facilitates prosocial behavior and reduces stress."
    },
    {
      "@id": "ns:Vasopressin",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Vasopressin",
      "rdfs:comment": "Vasopressin (antidiuretic hormone) regulates water balance and also acts as neurotransmitter affecting social behavior, memory, and aggression. It is synthesized in hypothalamus like oxytocin. Vasopressin and oxytocin have similar structures but distinct receptor distributions and behavioral effects. Vasopressin is implicated in pair bonding in voles."
    },
    {
      "@id": "ns:Orexin",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Orexin",
      "rdfs:comment": "Orexin (hypocretin) is synthesized by hypothalamic neurons regulating arousal, wakefulness, and feeding. Orexin neurons project widely and are active during waking. Orexin deficiency causes narcolepsy with cataplexy. Orexin stabilizes wake-sleep transitions and integrates metabolic and arousal states. Orexin antagonists are sleep aids."
    },
    {
      "@id": "ns:Endocannabinoid",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Endocannabinoid",
      "rdfs:comment": "Endocannabinoids are retrograde messengers synthesized postsynaptically and acting on presynaptic CB1 receptors to suppress transmitter release. They mediate depolarization-induced suppression of inhibition and excitation (DSI/DSE). Endocannabinoids regulate synaptic plasticity, pain, appetite, and mood. They are targets for therapeutic interventions."
    },
    {
      "@id": "ns:NitricOxide",
      "@type": [
        "owl:NamedIndividual",
        "ns:Neurotransmitter"
      ],
      "rdfs:label": "Nitric Oxide",
      "rdfs:comment": "Nitric oxide is a gaseous messenger synthesized by nitric oxide synthase and diffusing to nearby cells. It activates guanylyl cyclase producing cGMP. NO may act as retrograde messenger in LTP. It regulates cerebral blood flow coupling activity to metabolism. NO has diverse roles in development, plasticity, and neurovascular coupling."
    }
  ]
}